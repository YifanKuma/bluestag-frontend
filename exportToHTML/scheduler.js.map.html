<html>
<head>
<title>scheduler.js.map</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #080808;}
.s1 { color: #067d17;}
.s2 { color: #1750eb;}
.s3 { color: #0037a6;}
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
scheduler.js.map</font>
</center></td></tr></table>
<pre><span class="s0">{</span><span class="s1">&quot;version&quot;</span><span class="s0">:</span><span class="s2">3</span><span class="s0">,</span><span class="s1">&quot;sources&quot;</span><span class="s0">:[</span><span class="s1">&quot;../../../../src/client/components/segment-cache-impl/scheduler.ts&quot;</span><span class="s0">],</span><span class="s1">&quot;sourcesContent&quot;</span><span class="s0">:[</span><span class="s1">&quot;import type {</span><span class="s3">\n  </span><span class="s1">FlightRouterState,</span><span class="s3">\n  </span><span class="s1">Segment as FlightRouterStateSegment,</span><span class="s3">\n  </span><span class="s1">Segment,</span><span class="s3">\n</span><span class="s1">} from '../../../server/app-render/types'</span><span class="s3">\n</span><span class="s1">import { HasLoadingBoundary } from '../../../server/app-render/types'</span><span class="s3">\n</span><span class="s1">import { matchSegment } from '../match-segments'</span><span class="s3">\n</span><span class="s1">import {</span><span class="s3">\n  </span><span class="s1">readOrCreateRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">readOrCreateSegmentCacheEntry,</span><span class="s3">\n  </span><span class="s1">fetchRouteOnCacheMiss,</span><span class="s3">\n  </span><span class="s1">fetchSegmentOnCacheMiss,</span><span class="s3">\n  </span><span class="s1">EntryStatus,</span><span class="s3">\n  </span><span class="s1">type FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">type RouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">type SegmentCacheEntry,</span><span class="s3">\n  </span><span class="s1">type RouteTree,</span><span class="s3">\n  </span><span class="s1">fetchSegmentPrefetchesUsingDynamicRequest,</span><span class="s3">\n  </span><span class="s1">type PendingSegmentCacheEntry,</span><span class="s3">\n  </span><span class="s1">convertRouteTreeToFlightRouterState,</span><span class="s3">\n  </span><span class="s1">readOrCreateRevalidatingSegmentEntry,</span><span class="s3">\n  </span><span class="s1">upsertSegmentEntry,</span><span class="s3">\n  </span><span class="s1">type FulfilledSegmentCacheEntry,</span><span class="s3">\n  </span><span class="s1">upgradeToPendingSegment,</span><span class="s3">\n  </span><span class="s1">waitForSegmentCacheEntry,</span><span class="s3">\n  </span><span class="s1">resetRevalidatingSegmentEntry,</span><span class="s3">\n  </span><span class="s1">getSegmentKeypathForTask,</span><span class="s3">\n  </span><span class="s1">canNewFetchStrategyProvideMoreContent,</span><span class="s3">\n</span><span class="s1">} from './cache'</span><span class="s3">\n</span><span class="s1">import type { RouteCacheKey } from './cache-key'</span><span class="s3">\n</span><span class="s1">import {</span><span class="s3">\n  </span><span class="s1">FetchStrategy,</span><span class="s3">\n  </span><span class="s1">type PrefetchTaskFetchStrategy,</span><span class="s3">\n  </span><span class="s1">getCurrentCacheVersion,</span><span class="s3">\n  </span><span class="s1">PrefetchPriority,</span><span class="s3">\n</span><span class="s1">} from '../segment-cache'</span><span class="s3">\n</span><span class="s1">import {</span><span class="s3">\n  </span><span class="s1">addSearchParamsIfPageSegment,</span><span class="s3">\n  </span><span class="s1">PAGE_SEGMENT_KEY,</span><span class="s3">\n</span><span class="s1">} from '../../../shared/lib/segment'</span><span class="s3">\n</span><span class="s1">import type { SegmentCacheKey } from '../../../shared/lib/segment-cache/segment-value-encoding'</span><span class="s3">\n\n</span><span class="s1">const scheduleMicrotask =</span><span class="s3">\n  </span><span class="s1">typeof queueMicrotask === 'function'</span><span class="s3">\n    </span><span class="s1">? queueMicrotask</span><span class="s3">\n    </span><span class="s1">: (fn: () =&gt; unknown) =&gt;</span><span class="s3">\n        </span><span class="s1">Promise.resolve()</span><span class="s3">\n          </span><span class="s1">.then(fn)</span><span class="s3">\n          </span><span class="s1">.catch((error) =&gt;</span><span class="s3">\n            </span><span class="s1">setTimeout(() =&gt; {</span><span class="s3">\n              </span><span class="s1">throw error</span><span class="s3">\n            </span><span class="s1">})</span><span class="s3">\n          </span><span class="s1">)</span><span class="s3">\n\n</span><span class="s1">export type PrefetchTask = {</span><span class="s3">\n  </span><span class="s1">key: RouteCacheKey</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* The FlightRouterState at the time the task was initiated. This is needed</span><span class="s3">\n   </span><span class="s1">* when falling back to the non-PPR behavior, which only prefetches up to</span><span class="s3">\n   </span><span class="s1">* the first loading boundary.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">treeAtTimeOfPrefetch: FlightRouterState</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* The cache version at the time the task was initiated. This is used to</span><span class="s3">\n   </span><span class="s1">* determine if the cache was invalidated since the task was initiated.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">cacheVersion: number</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* Whether to prefetch dynamic data, in addition to static data. This is</span><span class="s3">\n   </span><span class="s1">* used by `&lt;Link prefetch={true}&gt;`.</span><span class="s3">\n   </span><span class="s1">*</span><span class="s3">\n   </span><span class="s1">* Note that a task with `FetchStrategy.PPR` might need to use</span><span class="s3">\n   </span><span class="s1">* `FetchStrategy.LoadingBoundary` instead if we find out that a route</span><span class="s3">\n   </span><span class="s1">* does not support PPR after doing the initial route prefetch.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">fetchStrategy: PrefetchTaskFetchStrategy</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* sortId is an incrementing counter</span><span class="s3">\n   </span><span class="s1">*</span><span class="s3">\n   </span><span class="s1">* Newer prefetches are prioritized over older ones, so that as new links</span><span class="s3">\n   </span><span class="s1">* enter the viewport, they are not starved by older links that are no</span><span class="s3">\n   </span><span class="s1">* longer relevant. In the future, we can add additional prioritization</span><span class="s3">\n   </span><span class="s1">* heuristics, like removing prefetches once a link leaves the viewport.</span><span class="s3">\n   </span><span class="s1">*</span><span class="s3">\n   </span><span class="s1">* The sortId is assigned when the prefetch is initiated, and reassigned if</span><span class="s3">\n   </span><span class="s1">* the same task is prefetched again (effectively bumping it to the top of</span><span class="s3">\n   </span><span class="s1">* the queue).</span><span class="s3">\n   </span><span class="s1">*</span><span class="s3">\n   </span><span class="s1">* TODO: We can add additional fields here to indicate what kind of prefetch</span><span class="s3">\n   </span><span class="s1">* it is. For example, was it initiated by a link? Or was it an imperative</span><span class="s3">\n   </span><span class="s1">* call? If it was initiated by a link, we can remove it from the queue when</span><span class="s3">\n   </span><span class="s1">* the link leaves the viewport, but if it was an imperative call, then we</span><span class="s3">\n   </span><span class="s1">* should keep it in the queue until it's fulfilled.</span><span class="s3">\n   </span><span class="s1">*</span><span class="s3">\n   </span><span class="s1">* We can also add priority levels. For example, hovering over a link could</span><span class="s3">\n   </span><span class="s1">* increase the priority of its prefetch.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">sortId: number</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* The priority of the task. Like sortId, this affects the task's position in</span><span class="s3">\n   </span><span class="s1">* the queue, so it must never be updated without resifting the heap.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">priority: PrefetchPriority</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* The phase of the task. Tasks are split into multiple phases so that their</span><span class="s3">\n   </span><span class="s1">* priority can be adjusted based on what kind of work they're doing.</span><span class="s3">\n   </span><span class="s1">* Concretely, prefetching the route tree is higher priority than prefetching</span><span class="s3">\n   </span><span class="s1">* segment data.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">phase: PrefetchPhase</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* Temporary state for tracking the currently running task. This is currently</span><span class="s3">\n   </span><span class="s1">* used to track whether a task deferred some work to run background at</span><span class="s3">\n   </span><span class="s1">* priority, but we might need it for additional state in the future.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">hasBackgroundWork: boolean</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* True if the prefetch was cancelled.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">isCanceled: boolean</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* The callback passed to `router.prefetch`, if given.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">onInvalidate: null | (() =&gt; void)</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* The index of the task in the heap's backing array. Used to efficiently</span><span class="s3">\n   </span><span class="s1">* change the priority of a task by re-sifting it, which requires knowing</span><span class="s3">\n   </span><span class="s1">* where it is in the array. This is only used internally by the heap</span><span class="s3">\n   </span><span class="s1">* algorithm. The naive alternative is indexOf every time a task is queued,</span><span class="s3">\n   </span><span class="s1">* which has O(n) complexity.</span><span class="s3">\n   </span><span class="s1">*</span><span class="s3">\n   </span><span class="s1">* We also use this field to check whether a task is currently in the queue.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">_heapIndex: number</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">const enum PrefetchTaskExitStatus {</span><span class="s3">\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* The task yielded because there are too many requests in progress.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">InProgress,</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* The task is blocked. It needs more data before it can proceed.</span><span class="s3">\n   </span><span class="s1">*</span><span class="s3">\n   </span><span class="s1">* Currently the only reason this happens is we're still waiting to receive a</span><span class="s3">\n   </span><span class="s1">* route tree from the server, because we can't start prefetching the segments</span><span class="s3">\n   </span><span class="s1">* until we know what to prefetch.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">Blocked,</span><span class="s3">\n\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* There's nothing left to prefetch.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">Done,</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">/**</span><span class="s3">\n </span><span class="s1">* Prefetch tasks are processed in two phases: first the route tree is fetched,</span><span class="s3">\n </span><span class="s1">* then the segments. We use this to priortize tasks that have not yet fetched</span><span class="s3">\n </span><span class="s1">* the route tree.</span><span class="s3">\n </span><span class="s1">*/</span><span class="s3">\n</span><span class="s1">const enum PrefetchPhase {</span><span class="s3">\n  </span><span class="s1">RouteTree = 1,</span><span class="s3">\n  </span><span class="s1">Segments = 0,</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">export type PrefetchSubtaskResult&lt;T&gt; = {</span><span class="s3">\n  </span><span class="s1">/**</span><span class="s3">\n   </span><span class="s1">* A promise that resolves when the network connection is closed.</span><span class="s3">\n   </span><span class="s1">*/</span><span class="s3">\n  </span><span class="s1">closed: Promise&lt;void&gt;</span><span class="s3">\n  </span><span class="s1">value: T</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">const taskHeap: Array&lt;PrefetchTask&gt; = []</span><span class="s3">\n\n</span><span class="s1">let inProgressRequests = 0</span><span class="s3">\n\n</span><span class="s1">let sortIdCounter = 0</span><span class="s3">\n</span><span class="s1">let didScheduleMicrotask = false</span><span class="s3">\n\n</span><span class="s1">// The most recently hovered (or touched, etc) link, i.e. the most recent task</span><span class="s3">\n</span><span class="s1">// scheduled at Intent priority. There's only ever a single task at Intent</span><span class="s3">\n</span><span class="s1">// priority at a time. We reserve special network bandwidth for this task only.</span><span class="s3">\n</span><span class="s1">let mostRecentlyHoveredLink: PrefetchTask | null = null</span><span class="s3">\n\n</span><span class="s1">export type IncludeDynamicData = null | 'full' | 'dynamic'</span><span class="s3">\n\n</span><span class="s1">/**</span><span class="s3">\n </span><span class="s1">* Initiates a prefetch task for the given URL. If a prefetch for the same URL</span><span class="s3">\n </span><span class="s1">* is already in progress, this will bump it to the top of the queue.</span><span class="s3">\n </span><span class="s1">*</span><span class="s3">\n </span><span class="s1">* This is not a user-facing function. By the time this is called, the href is</span><span class="s3">\n </span><span class="s1">* expected to be validated and normalized.</span><span class="s3">\n </span><span class="s1">*</span><span class="s3">\n </span><span class="s1">* @param key The RouteCacheKey to prefetch.</span><span class="s3">\n </span><span class="s1">* @param treeAtTimeOfPrefetch The app's current FlightRouterState</span><span class="s3">\n </span><span class="s1">* @param fetchStrategy Whether to prefetch dynamic data, in addition to</span><span class="s3">\n </span><span class="s1">* static data. This is used by `&lt;Link prefetch={true}&gt;`.</span><span class="s3">\n </span><span class="s1">*/</span><span class="s3">\n</span><span class="s1">export function schedulePrefetchTask(</span><span class="s3">\n  </span><span class="s1">key: RouteCacheKey,</span><span class="s3">\n  </span><span class="s1">treeAtTimeOfPrefetch: FlightRouterState,</span><span class="s3">\n  </span><span class="s1">fetchStrategy: PrefetchTaskFetchStrategy,</span><span class="s3">\n  </span><span class="s1">priority: PrefetchPriority,</span><span class="s3">\n  </span><span class="s1">onInvalidate: null | (() =&gt; void)</span><span class="s3">\n</span><span class="s1">): PrefetchTask {</span><span class="s3">\n  </span><span class="s1">// Spawn a new prefetch task</span><span class="s3">\n  </span><span class="s1">const task: PrefetchTask = {</span><span class="s3">\n    </span><span class="s1">key,</span><span class="s3">\n    </span><span class="s1">treeAtTimeOfPrefetch,</span><span class="s3">\n    </span><span class="s1">cacheVersion: getCurrentCacheVersion(),</span><span class="s3">\n    </span><span class="s1">priority,</span><span class="s3">\n    </span><span class="s1">phase: PrefetchPhase.RouteTree,</span><span class="s3">\n    </span><span class="s1">hasBackgroundWork: false,</span><span class="s3">\n    </span><span class="s1">fetchStrategy,</span><span class="s3">\n    </span><span class="s1">sortId: sortIdCounter++,</span><span class="s3">\n    </span><span class="s1">isCanceled: false,</span><span class="s3">\n    </span><span class="s1">onInvalidate,</span><span class="s3">\n    </span><span class="s1">_heapIndex: -1,</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n\n  </span><span class="s1">trackMostRecentlyHoveredLink(task)</span><span class="s3">\n\n  </span><span class="s1">heapPush(taskHeap, task)</span><span class="s3">\n\n  </span><span class="s1">// Schedule an async task to process the queue.</span><span class="s3">\n  </span><span class="s1">//</span><span class="s3">\n  </span><span class="s1">// The main reason we process the queue in an async task is for batching.</span><span class="s3">\n  </span><span class="s1">// It's common for a single JS task/event to trigger multiple prefetches.</span><span class="s3">\n  </span><span class="s1">// By deferring to a microtask, we only process the queue once per JS task.</span><span class="s3">\n  </span><span class="s1">// If they have different priorities, it also ensures they are processed in</span><span class="s3">\n  </span><span class="s1">// the optimal order.</span><span class="s3">\n  </span><span class="s1">ensureWorkIsScheduled()</span><span class="s3">\n\n  </span><span class="s1">return task</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">export function cancelPrefetchTask(task: PrefetchTask): void {</span><span class="s3">\n  </span><span class="s1">// Remove the prefetch task from the queue. If the task already completed,</span><span class="s3">\n  </span><span class="s1">// then this is a no-op.</span><span class="s3">\n  </span><span class="s1">//</span><span class="s3">\n  </span><span class="s1">// We must also explicitly mark the task as canceled so that a blocked task</span><span class="s3">\n  </span><span class="s1">// does not get added back to the queue when it's pinged by the network.</span><span class="s3">\n  </span><span class="s1">task.isCanceled = true</span><span class="s3">\n  </span><span class="s1">heapDelete(taskHeap, task)</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">export function reschedulePrefetchTask(</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">treeAtTimeOfPrefetch: FlightRouterState,</span><span class="s3">\n  </span><span class="s1">fetchStrategy: PrefetchTaskFetchStrategy,</span><span class="s3">\n  </span><span class="s1">priority: PrefetchPriority</span><span class="s3">\n</span><span class="s1">): void {</span><span class="s3">\n  </span><span class="s1">// Bump the prefetch task to the top of the queue, as if it were a fresh</span><span class="s3">\n  </span><span class="s1">// task. This is essentially the same as canceling the task and scheduling</span><span class="s3">\n  </span><span class="s1">// a new one, except it reuses the original object.</span><span class="s3">\n  </span><span class="s1">//</span><span class="s3">\n  </span><span class="s1">// The primary use case is to increase the priority of a Link-initated</span><span class="s3">\n  </span><span class="s1">// prefetch on hover.</span><span class="s3">\n\n  </span><span class="s1">// Un-cancel the task, in case it was previously canceled.</span><span class="s3">\n  </span><span class="s1">task.isCanceled = false</span><span class="s3">\n  </span><span class="s1">task.phase = PrefetchPhase.RouteTree</span><span class="s3">\n\n  </span><span class="s1">// Assign a new sort ID to move it ahead of all other tasks at the same</span><span class="s3">\n  </span><span class="s1">// priority level. (Higher sort IDs are processed first.)</span><span class="s3">\n  </span><span class="s1">task.sortId = sortIdCounter++</span><span class="s3">\n  </span><span class="s1">task.priority =</span><span class="s3">\n    </span><span class="s1">// If this task is the most recently hovered link, maintain its</span><span class="s3">\n    </span><span class="s1">// Intent priority, even if the rescheduled priority is lower.</span><span class="s3">\n    </span><span class="s1">task === mostRecentlyHoveredLink ? PrefetchPriority.Intent : priority</span><span class="s3">\n\n  </span><span class="s1">task.treeAtTimeOfPrefetch = treeAtTimeOfPrefetch</span><span class="s3">\n  </span><span class="s1">task.fetchStrategy = fetchStrategy</span><span class="s3">\n\n  </span><span class="s1">trackMostRecentlyHoveredLink(task)</span><span class="s3">\n\n  </span><span class="s1">if (task._heapIndex !== -1) {</span><span class="s3">\n    </span><span class="s1">// The task is already in the queue.</span><span class="s3">\n    </span><span class="s1">heapResift(taskHeap, task)</span><span class="s3">\n  </span><span class="s1">} else {</span><span class="s3">\n    </span><span class="s1">heapPush(taskHeap, task)</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">ensureWorkIsScheduled()</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">export function isPrefetchTaskDirty(</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">nextUrl: string | null,</span><span class="s3">\n  </span><span class="s1">tree: FlightRouterState</span><span class="s3">\n</span><span class="s1">): boolean {</span><span class="s3">\n  </span><span class="s1">// This is used to quickly bail out of a prefetch task if the result is</span><span class="s3">\n  </span><span class="s1">// guaranteed to not have changed since the task was initiated. This is</span><span class="s3">\n  </span><span class="s1">// strictly an optimization — theoretically, if it always returned true, no</span><span class="s3">\n  </span><span class="s1">// behavior should change because a full prefetch task will effectively</span><span class="s3">\n  </span><span class="s1">// perform the same checks.</span><span class="s3">\n  </span><span class="s1">const currentCacheVersion = getCurrentCacheVersion()</span><span class="s3">\n  </span><span class="s1">return (</span><span class="s3">\n    </span><span class="s1">task.cacheVersion !== currentCacheVersion ||</span><span class="s3">\n    </span><span class="s1">task.treeAtTimeOfPrefetch !== tree ||</span><span class="s3">\n    </span><span class="s1">task.key.nextUrl !== nextUrl</span><span class="s3">\n  </span><span class="s1">)</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function trackMostRecentlyHoveredLink(task: PrefetchTask) {</span><span class="s3">\n  </span><span class="s1">// Track the mostly recently hovered link, i.e. the most recently scheduled</span><span class="s3">\n  </span><span class="s1">// task at Intent priority. There must only be one such task at a time.</span><span class="s3">\n  </span><span class="s1">if (</span><span class="s3">\n    </span><span class="s1">task.priority === PrefetchPriority.Intent &amp;&amp;</span><span class="s3">\n    </span><span class="s1">task !== mostRecentlyHoveredLink</span><span class="s3">\n  </span><span class="s1">) {</span><span class="s3">\n    </span><span class="s1">if (mostRecentlyHoveredLink !== null) {</span><span class="s3">\n      </span><span class="s1">// Bump the previously hovered link's priority down to Default.</span><span class="s3">\n      </span><span class="s1">if (mostRecentlyHoveredLink.priority !== PrefetchPriority.Background) {</span><span class="s3">\n        </span><span class="s1">mostRecentlyHoveredLink.priority = PrefetchPriority.Default</span><span class="s3">\n        </span><span class="s1">heapResift(taskHeap, mostRecentlyHoveredLink)</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">mostRecentlyHoveredLink = task</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function ensureWorkIsScheduled() {</span><span class="s3">\n  </span><span class="s1">if (didScheduleMicrotask) {</span><span class="s3">\n    </span><span class="s1">// Already scheduled a task to process the queue</span><span class="s3">\n    </span><span class="s1">return</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">didScheduleMicrotask = true</span><span class="s3">\n  </span><span class="s1">scheduleMicrotask(processQueueInMicrotask)</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">/**</span><span class="s3">\n </span><span class="s1">* Checks if we've exceeded the maximum number of concurrent prefetch requests,</span><span class="s3">\n </span><span class="s1">* to avoid saturating the browser's internal network queue. This is a</span><span class="s3">\n </span><span class="s1">* cooperative limit — prefetch tasks should check this before issuing</span><span class="s3">\n </span><span class="s1">* new requests.</span><span class="s3">\n </span><span class="s1">*/</span><span class="s3">\n</span><span class="s1">function hasNetworkBandwidth(task: PrefetchTask): boolean {</span><span class="s3">\n  </span><span class="s1">// TODO: Also check if there's an in-progress navigation. We should never</span><span class="s3">\n  </span><span class="s1">// add prefetch requests to the network queue if an actual navigation is</span><span class="s3">\n  </span><span class="s1">// taking place, to ensure there's sufficient bandwidth for render-blocking</span><span class="s3">\n  </span><span class="s1">// data and resources.</span><span class="s3">\n\n  </span><span class="s1">// TODO: Consider reserving some amount of bandwidth for static prefetches.</span><span class="s3">\n\n  </span><span class="s1">if (task.priority === PrefetchPriority.Intent) {</span><span class="s3">\n    </span><span class="s1">// The most recently hovered link is allowed to exceed the default limit.</span><span class="s3">\n    </span><span class="s1">//</span><span class="s3">\n    </span><span class="s1">// The goal is to always have enough bandwidth to start a new prefetch</span><span class="s3">\n    </span><span class="s1">// request when hovering over a link.</span><span class="s3">\n    </span><span class="s1">//</span><span class="s3">\n    </span><span class="s1">// However, because we don't abort in-progress requests, it's still possible</span><span class="s3">\n    </span><span class="s1">// we'll run out of bandwidth. When links are hovered in quick succession,</span><span class="s3">\n    </span><span class="s1">// there could be multiple hover requests running simultaneously.</span><span class="s3">\n    </span><span class="s1">return inProgressRequests &lt; 12</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n\n  </span><span class="s1">// The default limit is lower than the limit for a hovered link.</span><span class="s3">\n  </span><span class="s1">return inProgressRequests &lt; 4</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function spawnPrefetchSubtask&lt;T&gt;(</span><span class="s3">\n  </span><span class="s1">prefetchSubtask: Promise&lt;PrefetchSubtaskResult&lt;T&gt; | null&gt;</span><span class="s3">\n</span><span class="s1">): Promise&lt;T | null&gt; {</span><span class="s3">\n  </span><span class="s1">// When the scheduler spawns an async task, we don't await its result.</span><span class="s3">\n  </span><span class="s1">// Instead, the async task writes its result directly into the cache, then</span><span class="s3">\n  </span><span class="s1">// pings the scheduler to continue.</span><span class="s3">\n  </span><span class="s1">//</span><span class="s3">\n  </span><span class="s1">// We process server responses streamingly, so the prefetch subtask will</span><span class="s3">\n  </span><span class="s1">// likely resolve before we're finished receiving all the data. The subtask</span><span class="s3">\n  </span><span class="s1">// result includes a promise that resolves once the network connection is</span><span class="s3">\n  </span><span class="s1">// closed. The scheduler uses this to control network bandwidth by tracking</span><span class="s3">\n  </span><span class="s1">// and limiting the number of concurrent requests.</span><span class="s3">\n  </span><span class="s1">inProgressRequests++</span><span class="s3">\n  </span><span class="s1">return prefetchSubtask.then((result) =&gt; {</span><span class="s3">\n    </span><span class="s1">if (result === null) {</span><span class="s3">\n      </span><span class="s1">// The prefetch task errored before it could start processing the</span><span class="s3">\n      </span><span class="s1">// network stream. Assume the connection is closed.</span><span class="s3">\n      </span><span class="s1">onPrefetchConnectionClosed()</span><span class="s3">\n      </span><span class="s1">return null</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">// Wait for the connection to close before freeing up more bandwidth.</span><span class="s3">\n    </span><span class="s1">result.closed.then(onPrefetchConnectionClosed)</span><span class="s3">\n    </span><span class="s1">return result.value</span><span class="s3">\n  </span><span class="s1">})</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function onPrefetchConnectionClosed(): void {</span><span class="s3">\n  </span><span class="s1">inProgressRequests--</span><span class="s3">\n\n  </span><span class="s1">// Notify the scheduler that we have more bandwidth, and can continue</span><span class="s3">\n  </span><span class="s1">// processing tasks.</span><span class="s3">\n  </span><span class="s1">ensureWorkIsScheduled()</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">/**</span><span class="s3">\n </span><span class="s1">* Notify the scheduler that we've received new data for an in-progress</span><span class="s3">\n </span><span class="s1">* prefetch. The corresponding task will be added back to the queue (unless the</span><span class="s3">\n </span><span class="s1">* task has been canceled in the meantime).</span><span class="s3">\n </span><span class="s1">*/</span><span class="s3">\n</span><span class="s1">export function pingPrefetchTask(task: PrefetchTask) {</span><span class="s3">\n  </span><span class="s1">// </span><span class="s3">\&quot;</span><span class="s1">Ping</span><span class="s3">\&quot; </span><span class="s1">a prefetch that's already in progress to notify it of new data.</span><span class="s3">\n  </span><span class="s1">if (</span><span class="s3">\n    </span><span class="s1">// Check if prefetch was canceled.</span><span class="s3">\n    </span><span class="s1">task.isCanceled ||</span><span class="s3">\n    </span><span class="s1">// Check if prefetch is already queued.</span><span class="s3">\n    </span><span class="s1">task._heapIndex !== -1</span><span class="s3">\n  </span><span class="s1">) {</span><span class="s3">\n    </span><span class="s1">return</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">// Add the task back to the queue.</span><span class="s3">\n  </span><span class="s1">heapPush(taskHeap, task)</span><span class="s3">\n  </span><span class="s1">ensureWorkIsScheduled()</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function processQueueInMicrotask() {</span><span class="s3">\n  </span><span class="s1">didScheduleMicrotask = false</span><span class="s3">\n\n  </span><span class="s1">// We aim to minimize how often we read the current time. Since nearly all</span><span class="s3">\n  </span><span class="s1">// functions in the prefetch scheduler are synchronous, we can read the time</span><span class="s3">\n  </span><span class="s1">// once and pass it as an argument wherever it's needed.</span><span class="s3">\n  </span><span class="s1">const now = Date.now()</span><span class="s3">\n\n  </span><span class="s1">// Process the task queue until we run out of network bandwidth.</span><span class="s3">\n  </span><span class="s1">let task = heapPeek(taskHeap)</span><span class="s3">\n  </span><span class="s1">while (task !== null &amp;&amp; hasNetworkBandwidth(task)) {</span><span class="s3">\n    </span><span class="s1">task.cacheVersion = getCurrentCacheVersion()</span><span class="s3">\n\n    </span><span class="s1">const route = readOrCreateRouteCacheEntry(now, task)</span><span class="s3">\n    </span><span class="s1">const exitStatus = pingRootRouteTree(now, task, route)</span><span class="s3">\n\n    </span><span class="s1">// The `hasBackgroundWork` field is only valid for a single attempt. Reset</span><span class="s3">\n    </span><span class="s1">// it immediately upon exit.</span><span class="s3">\n    </span><span class="s1">const hasBackgroundWork = task.hasBackgroundWork</span><span class="s3">\n    </span><span class="s1">task.hasBackgroundWork = false</span><span class="s3">\n\n    </span><span class="s1">switch (exitStatus) {</span><span class="s3">\n      </span><span class="s1">case PrefetchTaskExitStatus.InProgress:</span><span class="s3">\n        </span><span class="s1">// The task yielded because there are too many requests in progress.</span><span class="s3">\n        </span><span class="s1">// Stop processing tasks until we have more bandwidth.</span><span class="s3">\n        </span><span class="s1">return</span><span class="s3">\n      </span><span class="s1">case PrefetchTaskExitStatus.Blocked:</span><span class="s3">\n        </span><span class="s1">// The task is blocked. It needs more data before it can proceed.</span><span class="s3">\n        </span><span class="s1">// Keep the task out of the queue until the server responds.</span><span class="s3">\n        </span><span class="s1">heapPop(taskHeap)</span><span class="s3">\n        </span><span class="s1">// Continue to the next task</span><span class="s3">\n        </span><span class="s1">task = heapPeek(taskHeap)</span><span class="s3">\n        </span><span class="s1">continue</span><span class="s3">\n      </span><span class="s1">case PrefetchTaskExitStatus.Done:</span><span class="s3">\n        </span><span class="s1">if (task.phase === PrefetchPhase.RouteTree) {</span><span class="s3">\n          </span><span class="s1">// Finished prefetching the route tree. Proceed to prefetching</span><span class="s3">\n          </span><span class="s1">// the segments.</span><span class="s3">\n          </span><span class="s1">task.phase = PrefetchPhase.Segments</span><span class="s3">\n          </span><span class="s1">heapResift(taskHeap, task)</span><span class="s3">\n        </span><span class="s1">} else if (hasBackgroundWork) {</span><span class="s3">\n          </span><span class="s1">// The task spawned additional background work. Reschedule the task</span><span class="s3">\n          </span><span class="s1">// at background priority.</span><span class="s3">\n          </span><span class="s1">task.priority = PrefetchPriority.Background</span><span class="s3">\n          </span><span class="s1">heapResift(taskHeap, task)</span><span class="s3">\n        </span><span class="s1">} else {</span><span class="s3">\n          </span><span class="s1">// The prefetch is complete. Continue to the next task.</span><span class="s3">\n          </span><span class="s1">heapPop(taskHeap)</span><span class="s3">\n        </span><span class="s1">}</span><span class="s3">\n        </span><span class="s1">task = heapPeek(taskHeap)</span><span class="s3">\n        </span><span class="s1">continue</span><span class="s3">\n      </span><span class="s1">default:</span><span class="s3">\n        </span><span class="s1">exitStatus satisfies never</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">/**</span><span class="s3">\n </span><span class="s1">* Check this during a prefetch task to determine if background work can be</span><span class="s3">\n </span><span class="s1">* performed. If so, it evaluates to `true`. Otherwise, it returns `false`,</span><span class="s3">\n </span><span class="s1">* while also scheduling a background task to run later. Usage:</span><span class="s3">\n </span><span class="s1">*</span><span class="s3">\n </span><span class="s1">* @example</span><span class="s3">\n </span><span class="s1">* if (background(task)) {</span><span class="s3">\n </span><span class="s1">*   // Perform background-pri work</span><span class="s3">\n </span><span class="s1">* }</span><span class="s3">\n </span><span class="s1">*/</span><span class="s3">\n</span><span class="s1">function background(task: PrefetchTask): boolean {</span><span class="s3">\n  </span><span class="s1">if (task.priority === PrefetchPriority.Background) {</span><span class="s3">\n    </span><span class="s1">return true</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">task.hasBackgroundWork = true</span><span class="s3">\n  </span><span class="s1">return false</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function pingRootRouteTree(</span><span class="s3">\n  </span><span class="s1">now: number,</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">route: RouteCacheEntry</span><span class="s3">\n</span><span class="s1">): PrefetchTaskExitStatus {</span><span class="s3">\n  </span><span class="s1">switch (route.status) {</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Empty: {</span><span class="s3">\n      </span><span class="s1">// Route is not yet cached, and there's no request already in progress.</span><span class="s3">\n      </span><span class="s1">// Spawn a task to request the route, load it into the cache, and ping</span><span class="s3">\n      </span><span class="s1">// the task to continue.</span><span class="s3">\n\n      </span><span class="s1">// TODO: There are multiple strategies in the &lt;Link&gt; API for prefetching</span><span class="s3">\n      </span><span class="s1">// a route. Currently we've only implemented the main one: per-segment,</span><span class="s3">\n      </span><span class="s1">// static-data only.</span><span class="s3">\n      </span><span class="s1">//</span><span class="s3">\n      </span><span class="s1">// There's also `&lt;Link prefetch={true}&gt;`</span><span class="s3">\n      </span><span class="s1">// which prefetch both static *and* dynamic data.</span><span class="s3">\n      </span><span class="s1">// Similarly, we need to fallback to the old, per-page</span><span class="s3">\n      </span><span class="s1">// behavior if PPR is disabled for a route (via the incremental opt-in).</span><span class="s3">\n      </span><span class="s1">//</span><span class="s3">\n      </span><span class="s1">// Those cases will be handled here.</span><span class="s3">\n      </span><span class="s1">spawnPrefetchSubtask(fetchRouteOnCacheMiss(route, task))</span><span class="s3">\n\n      </span><span class="s1">// If the request takes longer than a minute, a subsequent request should</span><span class="s3">\n      </span><span class="s1">// retry instead of waiting for this one. When the response is received,</span><span class="s3">\n      </span><span class="s1">// this value will be replaced by a new value based on the stale time sent</span><span class="s3">\n      </span><span class="s1">// from the server.</span><span class="s3">\n      </span><span class="s1">// TODO: We should probably also manually abort the fetch task, to reclaim</span><span class="s3">\n      </span><span class="s1">// server bandwidth.</span><span class="s3">\n      </span><span class="s1">route.staleAt = now + 60 * 1000</span><span class="s3">\n\n      </span><span class="s1">// Upgrade to Pending so we know there's already a request in progress</span><span class="s3">\n      </span><span class="s1">route.status = EntryStatus.Pending</span><span class="s3">\n\n      </span><span class="s1">// Intentional fallthrough to the Pending branch</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Pending: {</span><span class="s3">\n      </span><span class="s1">// Still pending. We can't start prefetching the segments until the route</span><span class="s3">\n      </span><span class="s1">// tree has loaded. Add the task to the set of blocked tasks so that it</span><span class="s3">\n      </span><span class="s1">// is notified when the route tree is ready.</span><span class="s3">\n      </span><span class="s1">const blockedTasks = route.blockedTasks</span><span class="s3">\n      </span><span class="s1">if (blockedTasks === null) {</span><span class="s3">\n        </span><span class="s1">route.blockedTasks = new Set([task])</span><span class="s3">\n      </span><span class="s1">} else {</span><span class="s3">\n        </span><span class="s1">blockedTasks.add(task)</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">return PrefetchTaskExitStatus.Blocked</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Rejected: {</span><span class="s3">\n      </span><span class="s1">// Route tree failed to load. Treat as a 404.</span><span class="s3">\n      </span><span class="s1">return PrefetchTaskExitStatus.Done</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Fulfilled: {</span><span class="s3">\n      </span><span class="s1">if (task.phase !== PrefetchPhase.Segments) {</span><span class="s3">\n        </span><span class="s1">// Do not prefetch segment data until we've entered the segment phase.</span><span class="s3">\n        </span><span class="s1">return PrefetchTaskExitStatus.Done</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">// Recursively fill in the segment tree.</span><span class="s3">\n      </span><span class="s1">if (!hasNetworkBandwidth(task)) {</span><span class="s3">\n        </span><span class="s1">// Stop prefetching segments until there's more bandwidth.</span><span class="s3">\n        </span><span class="s1">return PrefetchTaskExitStatus.InProgress</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">const tree = route.tree</span><span class="s3">\n\n      </span><span class="s1">// A task's fetch strategy gets set to `PPR` for any </span><span class="s3">\&quot;</span><span class="s1">auto</span><span class="s3">\&quot; </span><span class="s1">prefetch.</span><span class="s3">\n      </span><span class="s1">// If it turned out that the route isn't PPR-enabled, we need to use `LoadingBoundary` instead.</span><span class="s3">\n      </span><span class="s1">// We don't need to do this for runtime prefetches, because those are only available in</span><span class="s3">\n      </span><span class="s1">// `cacheComponents`, where every route is PPR.</span><span class="s3">\n      </span><span class="s1">const fetchStrategy =</span><span class="s3">\n        </span><span class="s1">task.fetchStrategy === FetchStrategy.PPR</span><span class="s3">\n          </span><span class="s1">? route.isPPREnabled</span><span class="s3">\n            </span><span class="s1">? FetchStrategy.PPR</span><span class="s3">\n            </span><span class="s1">: FetchStrategy.LoadingBoundary</span><span class="s3">\n          </span><span class="s1">: task.fetchStrategy</span><span class="s3">\n\n      </span><span class="s1">switch (fetchStrategy) {</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.PPR:</span><span class="s3">\n          </span><span class="s1">// Individually prefetch the static shell for each segment. This is</span><span class="s3">\n          </span><span class="s1">// the default prefetching behavior for static routes, or when PPR is</span><span class="s3">\n          </span><span class="s1">// enabled. It will not include any dynamic data.</span><span class="s3">\n          </span><span class="s1">return pingPPRRouteTree(now, task, route, tree)</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.Full:</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.PPRRuntime:</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.LoadingBoundary: {</span><span class="s3">\n          </span><span class="s1">// Prefetch multiple segments using a single dynamic request.</span><span class="s3">\n          </span><span class="s1">const spawnedEntries = new Map&lt;</span><span class="s3">\n            </span><span class="s1">SegmentCacheKey,</span><span class="s3">\n            </span><span class="s1">PendingSegmentCacheEntry</span><span class="s3">\n          </span><span class="s1">&gt;()</span><span class="s3">\n          </span><span class="s1">const dynamicRequestTree = diffRouteTreeAgainstCurrent(</span><span class="s3">\n            </span><span class="s1">now,</span><span class="s3">\n            </span><span class="s1">task,</span><span class="s3">\n            </span><span class="s1">route,</span><span class="s3">\n            </span><span class="s1">task.treeAtTimeOfPrefetch,</span><span class="s3">\n            </span><span class="s1">tree,</span><span class="s3">\n            </span><span class="s1">spawnedEntries,</span><span class="s3">\n            </span><span class="s1">fetchStrategy</span><span class="s3">\n          </span><span class="s1">)</span><span class="s3">\n\n          </span><span class="s1">let needsDynamicRequest = spawnedEntries.size &gt; 0</span><span class="s3">\n\n          </span><span class="s1">if (</span><span class="s3">\n            </span><span class="s1">!needsDynamicRequest &amp;&amp;</span><span class="s3">\n            </span><span class="s1">route.isHeadPartial &amp;&amp;</span><span class="s3">\n            </span><span class="s1">route.TODO_metadataStatus === EntryStatus.Empty</span><span class="s3">\n          </span><span class="s1">) {</span><span class="s3">\n            </span><span class="s1">// All the segment data is already cached, however, we need to issue</span><span class="s3">\n            </span><span class="s1">// a request anyway so we can prefetch the head. Update the status</span><span class="s3">\n            </span><span class="s1">// field to prevent additional requests from being spawned while</span><span class="s3">\n            </span><span class="s1">// this one is in progress.</span><span class="s3">\n            </span><span class="s1">// TODO: This is a temporary, targeted solution to fix a regression</span><span class="s3">\n            </span><span class="s1">// we found. It exists to prevent the scheduler from sending a</span><span class="s3">\n            </span><span class="s1">// redundant request if there's already one in progress.</span><span class="s3">\n            </span><span class="s1">// Essentially, it will attempt once at most, then give up until the</span><span class="s3">\n            </span><span class="s1">// route entry expires or is evicted by other means. But because</span><span class="s3">\n            </span><span class="s1">// this doesn't have its own stale time separate from the route</span><span class="s3">\n            </span><span class="s1">// itself, there will be edge cases where the metadata fails to be</span><span class="s3">\n            </span><span class="s1">// fully prefetched. Consider caching metadata using a separate</span><span class="s3">\n            </span><span class="s1">// entry type so we can model this more cleanly. The circumstances</span><span class="s3">\n            </span><span class="s1">// that lead to this branch running in the first place are</span><span class="s3">\n            </span><span class="s1">// relatively rare, so it's not critical.</span><span class="s3">\n            </span><span class="s1">route.TODO_metadataStatus = EntryStatus.Fulfilled</span><span class="s3">\n            </span><span class="s1">needsDynamicRequest = true</span><span class="s3">\n            </span><span class="s1">// This instructs the server to only send the metadata.</span><span class="s3">\n            </span><span class="s1">dynamicRequestTree[3] = 'metadata-only'</span><span class="s3">\n            </span><span class="s1">// We can null out the children to reduce the request size, since</span><span class="s3">\n            </span><span class="s1">// they won't be needed.</span><span class="s3">\n            </span><span class="s1">dynamicRequestTree[1] = {}</span><span class="s3">\n          </span><span class="s1">}</span><span class="s3">\n\n          </span><span class="s1">if (needsDynamicRequest) {</span><span class="s3">\n            </span><span class="s1">// Perform a dynamic prefetch request and populate the cache with</span><span class="s3">\n            </span><span class="s1">// the result</span><span class="s3">\n            </span><span class="s1">spawnPrefetchSubtask(</span><span class="s3">\n              </span><span class="s1">fetchSegmentPrefetchesUsingDynamicRequest(</span><span class="s3">\n                </span><span class="s1">task,</span><span class="s3">\n                </span><span class="s1">route,</span><span class="s3">\n                </span><span class="s1">fetchStrategy,</span><span class="s3">\n                </span><span class="s1">dynamicRequestTree,</span><span class="s3">\n                </span><span class="s1">spawnedEntries</span><span class="s3">\n              </span><span class="s1">)</span><span class="s3">\n            </span><span class="s1">)</span><span class="s3">\n          </span><span class="s1">}</span><span class="s3">\n          </span><span class="s1">return PrefetchTaskExitStatus.Done</span><span class="s3">\n        </span><span class="s1">}</span><span class="s3">\n        </span><span class="s1">default:</span><span class="s3">\n          </span><span class="s1">fetchStrategy satisfies never</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">default: {</span><span class="s3">\n      </span><span class="s1">route satisfies never</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">return PrefetchTaskExitStatus.Done</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function pingPPRRouteTree(</span><span class="s3">\n  </span><span class="s1">now: number,</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">tree: RouteTree</span><span class="s3">\n</span><span class="s1">): PrefetchTaskExitStatus.InProgress | PrefetchTaskExitStatus.Done {</span><span class="s3">\n  </span><span class="s1">const segment = readOrCreateSegmentCacheEntry(now, task, route, tree.cacheKey)</span><span class="s3">\n  </span><span class="s1">pingPerSegment(now, task, route, segment, task.key, tree)</span><span class="s3">\n  </span><span class="s1">if (tree.slots !== null) {</span><span class="s3">\n    </span><span class="s1">if (!hasNetworkBandwidth(task)) {</span><span class="s3">\n      </span><span class="s1">// Stop prefetching segments until there's more bandwidth.</span><span class="s3">\n      </span><span class="s1">return PrefetchTaskExitStatus.InProgress</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">// Recursively ping the children.</span><span class="s3">\n    </span><span class="s1">for (const parallelRouteKey in tree.slots) {</span><span class="s3">\n      </span><span class="s1">const childTree = tree.slots[parallelRouteKey]</span><span class="s3">\n      </span><span class="s1">const childExitStatus = pingPPRRouteTree(now, task, route, childTree)</span><span class="s3">\n      </span><span class="s1">if (childExitStatus === PrefetchTaskExitStatus.InProgress) {</span><span class="s3">\n        </span><span class="s1">// Child yielded without finishing.</span><span class="s3">\n        </span><span class="s1">return PrefetchTaskExitStatus.InProgress</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">// This segment and all its children have finished prefetching.</span><span class="s3">\n  </span><span class="s1">return PrefetchTaskExitStatus.Done</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function diffRouteTreeAgainstCurrent(</span><span class="s3">\n  </span><span class="s1">now: number,</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">oldTree: FlightRouterState,</span><span class="s3">\n  </span><span class="s1">newTree: RouteTree,</span><span class="s3">\n  </span><span class="s1">spawnedEntries: Map&lt;string, PendingSegmentCacheEntry&gt;,</span><span class="s3">\n  </span><span class="s1">fetchStrategy:</span><span class="s3">\n    </span><span class="s1">| FetchStrategy.Full</span><span class="s3">\n    </span><span class="s1">| FetchStrategy.PPRRuntime</span><span class="s3">\n    </span><span class="s1">| FetchStrategy.LoadingBoundary</span><span class="s3">\n</span><span class="s1">): FlightRouterState {</span><span class="s3">\n  </span><span class="s1">// This is a single recursive traversal that does multiple things:</span><span class="s3">\n  </span><span class="s1">// - Finds the parts of the target route (newTree) that are not part of</span><span class="s3">\n  </span><span class="s1">//   of the current page (oldTree) by diffing them, using the same algorithm</span><span class="s3">\n  </span><span class="s1">//   as a real navigation.</span><span class="s3">\n  </span><span class="s1">// - Constructs a request tree (FlightRouterState) that describes which</span><span class="s3">\n  </span><span class="s1">//   segments need to be prefetched and which ones are already cached.</span><span class="s3">\n  </span><span class="s1">// - Creates a set of pending cache entries for the segments that need to</span><span class="s3">\n  </span><span class="s1">//   be prefetched, so that a subsequent prefetch task does not request the</span><span class="s3">\n  </span><span class="s1">//   same segments again.</span><span class="s3">\n  </span><span class="s1">const oldTreeChildren = oldTree[1]</span><span class="s3">\n  </span><span class="s1">const newTreeChildren = newTree.slots</span><span class="s3">\n  </span><span class="s1">let requestTreeChildren: Record&lt;string, FlightRouterState&gt; = {}</span><span class="s3">\n  </span><span class="s1">if (newTreeChildren !== null) {</span><span class="s3">\n    </span><span class="s1">for (const parallelRouteKey in newTreeChildren) {</span><span class="s3">\n      </span><span class="s1">const newTreeChild = newTreeChildren[parallelRouteKey]</span><span class="s3">\n      </span><span class="s1">const newTreeChildSegment = newTreeChild.segment</span><span class="s3">\n      </span><span class="s1">const oldTreeChild: FlightRouterState | void =</span><span class="s3">\n        </span><span class="s1">oldTreeChildren[parallelRouteKey]</span><span class="s3">\n      </span><span class="s1">const oldTreeChildSegment: FlightRouterStateSegment | void =</span><span class="s3">\n        </span><span class="s1">oldTreeChild?.[0]</span><span class="s3">\n      </span><span class="s1">if (</span><span class="s3">\n        </span><span class="s1">oldTreeChildSegment !== undefined &amp;&amp;</span><span class="s3">\n        </span><span class="s1">doesCurrentSegmentMatchCachedSegment(</span><span class="s3">\n          </span><span class="s1">route,</span><span class="s3">\n          </span><span class="s1">newTreeChildSegment,</span><span class="s3">\n          </span><span class="s1">oldTreeChildSegment</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">) {</span><span class="s3">\n        </span><span class="s1">// This segment is already part of the current route. Keep traversing.</span><span class="s3">\n        </span><span class="s1">const requestTreeChild = diffRouteTreeAgainstCurrent(</span><span class="s3">\n          </span><span class="s1">now,</span><span class="s3">\n          </span><span class="s1">task,</span><span class="s3">\n          </span><span class="s1">route,</span><span class="s3">\n          </span><span class="s1">oldTreeChild,</span><span class="s3">\n          </span><span class="s1">newTreeChild,</span><span class="s3">\n          </span><span class="s1">spawnedEntries,</span><span class="s3">\n          </span><span class="s1">fetchStrategy</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n        </span><span class="s1">requestTreeChildren[parallelRouteKey] = requestTreeChild</span><span class="s3">\n      </span><span class="s1">} else {</span><span class="s3">\n        </span><span class="s1">// This segment is not part of the current route. We're entering a</span><span class="s3">\n        </span><span class="s1">// part of the tree that we need to prefetch (unless everything is</span><span class="s3">\n        </span><span class="s1">// already cached).</span><span class="s3">\n        </span><span class="s1">switch (fetchStrategy) {</span><span class="s3">\n          </span><span class="s1">case FetchStrategy.LoadingBoundary: {</span><span class="s3">\n            </span><span class="s1">// When PPR is disabled, we can't prefetch per segment. We must</span><span class="s3">\n            </span><span class="s1">// fallback to the old prefetch behavior and send a dynamic request.</span><span class="s3">\n            </span><span class="s1">// Only routes that include a loading boundary can be prefetched in</span><span class="s3">\n            </span><span class="s1">// this way.</span><span class="s3">\n            </span><span class="s1">//</span><span class="s3">\n            </span><span class="s1">// This is simlar to a </span><span class="s3">\&quot;</span><span class="s1">full</span><span class="s3">\&quot; </span><span class="s1">prefetch, but we're much more</span><span class="s3">\n            </span><span class="s1">// conservative about which segments to include in the request.</span><span class="s3">\n            </span><span class="s1">//</span><span class="s3">\n            </span><span class="s1">// The server will only render up to the first loading boundary</span><span class="s3">\n            </span><span class="s1">// inside new part of the tree. If there's no loading boundary</span><span class="s3">\n            </span><span class="s1">// anywhere in the tree, the server will never return any data, so</span><span class="s3">\n            </span><span class="s1">// we can skip the request.</span><span class="s3">\n            </span><span class="s1">const subtreeHasLoadingBoundary =</span><span class="s3">\n              </span><span class="s1">newTreeChild.hasLoadingBoundary !==</span><span class="s3">\n              </span><span class="s1">HasLoadingBoundary.SubtreeHasNoLoadingBoundary</span><span class="s3">\n            </span><span class="s1">const requestTreeChild = subtreeHasLoadingBoundary</span><span class="s3">\n              </span><span class="s1">? pingPPRDisabledRouteTreeUpToLoadingBoundary(</span><span class="s3">\n                  </span><span class="s1">now,</span><span class="s3">\n                  </span><span class="s1">task,</span><span class="s3">\n                  </span><span class="s1">route,</span><span class="s3">\n                  </span><span class="s1">newTreeChild,</span><span class="s3">\n                  </span><span class="s1">null,</span><span class="s3">\n                  </span><span class="s1">spawnedEntries</span><span class="s3">\n                </span><span class="s1">)</span><span class="s3">\n              </span><span class="s1">: // There's no loading boundary within this tree. Bail out.</span><span class="s3">\n                </span><span class="s1">convertRouteTreeToFlightRouterState(newTreeChild)</span><span class="s3">\n            </span><span class="s1">requestTreeChildren[parallelRouteKey] = requestTreeChild</span><span class="s3">\n            </span><span class="s1">break</span><span class="s3">\n          </span><span class="s1">}</span><span class="s3">\n          </span><span class="s1">case FetchStrategy.PPRRuntime: {</span><span class="s3">\n            </span><span class="s1">// This is a runtime prefetch. Fetch all cacheable data in the tree,</span><span class="s3">\n            </span><span class="s1">// not just the static PPR shell.</span><span class="s3">\n            </span><span class="s1">const requestTreeChild = pingRouteTreeAndIncludeDynamicData(</span><span class="s3">\n              </span><span class="s1">now,</span><span class="s3">\n              </span><span class="s1">task,</span><span class="s3">\n              </span><span class="s1">route,</span><span class="s3">\n              </span><span class="s1">newTreeChild,</span><span class="s3">\n              </span><span class="s1">false,</span><span class="s3">\n              </span><span class="s1">spawnedEntries,</span><span class="s3">\n              </span><span class="s1">fetchStrategy</span><span class="s3">\n            </span><span class="s1">)</span><span class="s3">\n            </span><span class="s1">requestTreeChildren[parallelRouteKey] = requestTreeChild</span><span class="s3">\n            </span><span class="s1">break</span><span class="s3">\n          </span><span class="s1">}</span><span class="s3">\n          </span><span class="s1">case FetchStrategy.Full: {</span><span class="s3">\n            </span><span class="s1">// This is a </span><span class="s3">\&quot;</span><span class="s1">full</span><span class="s3">\&quot; </span><span class="s1">prefetch. Fetch all the data in the tree, both</span><span class="s3">\n            </span><span class="s1">// static and dynamic. We issue roughly the same request that we</span><span class="s3">\n            </span><span class="s1">// would during a real navigation. The goal is that once the</span><span class="s3">\n            </span><span class="s1">// navigation occurs, the router should not have to fetch any</span><span class="s3">\n            </span><span class="s1">// additional data.</span><span class="s3">\n            </span><span class="s1">//</span><span class="s3">\n            </span><span class="s1">// Although the response will include dynamic data, opting into a</span><span class="s3">\n            </span><span class="s1">// Full prefetch — via &lt;Link prefetch={true}&gt; — implicitly</span><span class="s3">\n            </span><span class="s1">// instructs the cache to treat the response as </span><span class="s3">\&quot;</span><span class="s1">static</span><span class="s3">\&quot;</span><span class="s1">, or non-</span><span class="s3">\n            </span><span class="s1">// dynamic, since the whole point is to cache it for</span><span class="s3">\n            </span><span class="s1">// future navigations.</span><span class="s3">\n            </span><span class="s1">//</span><span class="s3">\n            </span><span class="s1">// Construct a tree (currently a FlightRouterState) that represents</span><span class="s3">\n            </span><span class="s1">// which segments need to be prefetched and which ones are already</span><span class="s3">\n            </span><span class="s1">// cached. If the tree is empty, then we can exit. Otherwise, we'll</span><span class="s3">\n            </span><span class="s1">// send the request tree to the server and use the response to</span><span class="s3">\n            </span><span class="s1">// populate the segment cache.</span><span class="s3">\n            </span><span class="s1">const requestTreeChild = pingRouteTreeAndIncludeDynamicData(</span><span class="s3">\n              </span><span class="s1">now,</span><span class="s3">\n              </span><span class="s1">task,</span><span class="s3">\n              </span><span class="s1">route,</span><span class="s3">\n              </span><span class="s1">newTreeChild,</span><span class="s3">\n              </span><span class="s1">false,</span><span class="s3">\n              </span><span class="s1">spawnedEntries,</span><span class="s3">\n              </span><span class="s1">fetchStrategy</span><span class="s3">\n            </span><span class="s1">)</span><span class="s3">\n            </span><span class="s1">requestTreeChildren[parallelRouteKey] = requestTreeChild</span><span class="s3">\n            </span><span class="s1">break</span><span class="s3">\n          </span><span class="s1">}</span><span class="s3">\n          </span><span class="s1">default:</span><span class="s3">\n            </span><span class="s1">fetchStrategy satisfies never</span><span class="s3">\n        </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">const requestTree: FlightRouterState = [</span><span class="s3">\n    </span><span class="s1">newTree.segment,</span><span class="s3">\n    </span><span class="s1">requestTreeChildren,</span><span class="s3">\n    </span><span class="s1">null,</span><span class="s3">\n    </span><span class="s1">null,</span><span class="s3">\n    </span><span class="s1">newTree.isRootLayout,</span><span class="s3">\n  </span><span class="s1">]</span><span class="s3">\n  </span><span class="s1">return requestTree</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function pingPPRDisabledRouteTreeUpToLoadingBoundary(</span><span class="s3">\n  </span><span class="s1">now: number,</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">tree: RouteTree,</span><span class="s3">\n  </span><span class="s1">refetchMarkerContext: 'refetch' | 'inside-shared-layout' | null,</span><span class="s3">\n  </span><span class="s1">spawnedEntries: Map&lt;string, PendingSegmentCacheEntry&gt;</span><span class="s3">\n</span><span class="s1">): FlightRouterState {</span><span class="s3">\n  </span><span class="s1">// This function is similar to pingRouteTreeAndIncludeDynamicData, except the</span><span class="s3">\n  </span><span class="s1">// server is only going to return a minimal loading state — it will stop</span><span class="s3">\n  </span><span class="s1">// rendering at the first loading boundary. Whereas a Full prefetch is</span><span class="s3">\n  </span><span class="s1">// intentionally aggressive and tries to pretfetch all the data that will be</span><span class="s3">\n  </span><span class="s1">// needed for a navigation, a LoadingBoundary prefetch is much more</span><span class="s3">\n  </span><span class="s1">// conservative. For example, it will omit from the request tree any segment</span><span class="s3">\n  </span><span class="s1">// that is already cached, regardles of whether it's partial or full. By</span><span class="s3">\n  </span><span class="s1">// contrast, a Full prefetch will refetch partial segments.</span><span class="s3">\n\n  </span><span class="s1">// </span><span class="s3">\&quot;</span><span class="s1">inside-shared-layout</span><span class="s3">\&quot; </span><span class="s1">tells the server where to start looking for a</span><span class="s3">\n  </span><span class="s1">// loading boundary.</span><span class="s3">\n  </span><span class="s1">let refetchMarker: 'refetch' | 'inside-shared-layout' | null =</span><span class="s3">\n    </span><span class="s1">refetchMarkerContext === null ? 'inside-shared-layout' : null</span><span class="s3">\n\n  </span><span class="s1">const segment = readOrCreateSegmentCacheEntry(now, task, route, tree.cacheKey)</span><span class="s3">\n  </span><span class="s1">switch (segment.status) {</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Empty: {</span><span class="s3">\n      </span><span class="s1">// This segment is not cached. Add a refetch marker so the server knows</span><span class="s3">\n      </span><span class="s1">// to start rendering here.</span><span class="s3">\n      </span><span class="s1">// TODO: Instead of a </span><span class="s3">\&quot;</span><span class="s1">refetch</span><span class="s3">\&quot; </span><span class="s1">marker, we could just omit this subtree's</span><span class="s3">\n      </span><span class="s1">// FlightRouterState from the request tree. I think this would probably</span><span class="s3">\n      </span><span class="s1">// already work even without any updates to the server. For consistency,</span><span class="s3">\n      </span><span class="s1">// though, I'll send the full tree and we'll look into this later as part</span><span class="s3">\n      </span><span class="s1">// of a larger redesign of the request protocol.</span><span class="s3">\n\n      </span><span class="s1">// Add the pending cache entry to the result map.</span><span class="s3">\n      </span><span class="s1">spawnedEntries.set(</span><span class="s3">\n        </span><span class="s1">tree.cacheKey,</span><span class="s3">\n        </span><span class="s1">upgradeToPendingSegment(</span><span class="s3">\n          </span><span class="s1">segment,</span><span class="s3">\n          </span><span class="s1">// Set the fetch strategy to LoadingBoundary to indicate that the server</span><span class="s3">\n          </span><span class="s1">// might not include it in the pending response. If another route is able</span><span class="s3">\n          </span><span class="s1">// to issue a per-segment request, we'll do that in the background.</span><span class="s3">\n          </span><span class="s1">FetchStrategy.LoadingBoundary</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">if (refetchMarkerContext !== 'refetch') {</span><span class="s3">\n        </span><span class="s1">refetchMarker = refetchMarkerContext = 'refetch'</span><span class="s3">\n      </span><span class="s1">} else {</span><span class="s3">\n        </span><span class="s1">// There's already a parent with a refetch marker, so we don't need</span><span class="s3">\n        </span><span class="s1">// to add another one.</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Fulfilled: {</span><span class="s3">\n      </span><span class="s1">// The segment is already cached.</span><span class="s3">\n      </span><span class="s1">const segmentHasLoadingBoundary =</span><span class="s3">\n        </span><span class="s1">tree.hasLoadingBoundary === HasLoadingBoundary.SegmentHasLoadingBoundary</span><span class="s3">\n      </span><span class="s1">if (segmentHasLoadingBoundary) {</span><span class="s3">\n        </span><span class="s1">// This segment has a loading boundary, which means the server won't</span><span class="s3">\n        </span><span class="s1">// render its children. So there's nothing left to prefetch along this</span><span class="s3">\n        </span><span class="s1">// path. We can bail out.</span><span class="s3">\n        </span><span class="s1">return convertRouteTreeToFlightRouterState(tree)</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">// NOTE: If the cached segment were fetched using PPR, then it might be</span><span class="s3">\n      </span><span class="s1">// partial. We could get a more complete version of the segment by</span><span class="s3">\n      </span><span class="s1">// including it in this non-PPR request.</span><span class="s3">\n      </span><span class="s1">//</span><span class="s3">\n      </span><span class="s1">// We're intentionally choosing not to, though, because it's generally</span><span class="s3">\n      </span><span class="s1">// better to avoid doing a full prefetch whenever possible.</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Pending: {</span><span class="s3">\n      </span><span class="s1">// There's another prefetch currently in progress. Don't add the refetch</span><span class="s3">\n      </span><span class="s1">// marker yet, so the server knows it can skip rendering this segment.</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Rejected: {</span><span class="s3">\n      </span><span class="s1">// The segment failed to load. We shouldn't issue another request until</span><span class="s3">\n      </span><span class="s1">// the stale time has elapsed.</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">default:</span><span class="s3">\n      </span><span class="s1">segment satisfies never</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">const requestTreeChildren: Record&lt;string, FlightRouterState&gt; = {}</span><span class="s3">\n  </span><span class="s1">if (tree.slots !== null) {</span><span class="s3">\n    </span><span class="s1">for (const parallelRouteKey in tree.slots) {</span><span class="s3">\n      </span><span class="s1">const childTree = tree.slots[parallelRouteKey]</span><span class="s3">\n      </span><span class="s1">requestTreeChildren[parallelRouteKey] =</span><span class="s3">\n        </span><span class="s1">pingPPRDisabledRouteTreeUpToLoadingBoundary(</span><span class="s3">\n          </span><span class="s1">now,</span><span class="s3">\n          </span><span class="s1">task,</span><span class="s3">\n          </span><span class="s1">route,</span><span class="s3">\n          </span><span class="s1">childTree,</span><span class="s3">\n          </span><span class="s1">refetchMarkerContext,</span><span class="s3">\n          </span><span class="s1">spawnedEntries</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">const requestTree: FlightRouterState = [</span><span class="s3">\n    </span><span class="s1">tree.segment,</span><span class="s3">\n    </span><span class="s1">requestTreeChildren,</span><span class="s3">\n    </span><span class="s1">null,</span><span class="s3">\n    </span><span class="s1">refetchMarker,</span><span class="s3">\n    </span><span class="s1">tree.isRootLayout,</span><span class="s3">\n  </span><span class="s1">]</span><span class="s3">\n  </span><span class="s1">return requestTree</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function pingRouteTreeAndIncludeDynamicData(</span><span class="s3">\n  </span><span class="s1">now: number,</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">tree: RouteTree,</span><span class="s3">\n  </span><span class="s1">isInsideRefetchingParent: boolean,</span><span class="s3">\n  </span><span class="s1">spawnedEntries: Map&lt;string, PendingSegmentCacheEntry&gt;,</span><span class="s3">\n  </span><span class="s1">fetchStrategy: FetchStrategy.Full | FetchStrategy.PPRRuntime</span><span class="s3">\n</span><span class="s1">): FlightRouterState {</span><span class="s3">\n  </span><span class="s1">// The tree we're constructing is the same shape as the tree we're navigating</span><span class="s3">\n  </span><span class="s1">// to. But even though this is a </span><span class="s3">\&quot;</span><span class="s1">new</span><span class="s3">\&quot; </span><span class="s1">tree, some of the individual segments</span><span class="s3">\n  </span><span class="s1">// may be cached as a result of other route prefetches.</span><span class="s3">\n  </span><span class="s1">//</span><span class="s3">\n  </span><span class="s1">// So we need to find the first uncached segment along each path add an</span><span class="s3">\n  </span><span class="s1">// explicit </span><span class="s3">\&quot;</span><span class="s1">refetch</span><span class="s3">\&quot; </span><span class="s1">marker so the server knows where to start rendering.</span><span class="s3">\n  </span><span class="s1">// Once the server starts rendering along a path, it keeps rendering the</span><span class="s3">\n  </span><span class="s1">// entire subtree.</span><span class="s3">\n  </span><span class="s1">const segment = readOrCreateSegmentCacheEntry(now, task, route, tree.cacheKey)</span><span class="s3">\n\n  </span><span class="s1">let spawnedSegment: PendingSegmentCacheEntry | null = null</span><span class="s3">\n\n  </span><span class="s1">switch (segment.status) {</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Empty: {</span><span class="s3">\n      </span><span class="s1">// This segment is not cached. Include it in the request.</span><span class="s3">\n      </span><span class="s1">spawnedSegment = upgradeToPendingSegment(segment, fetchStrategy)</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Fulfilled: {</span><span class="s3">\n      </span><span class="s1">// The segment is already cached.</span><span class="s3">\n      </span><span class="s1">if (</span><span class="s3">\n        </span><span class="s1">segment.isPartial &amp;&amp;</span><span class="s3">\n        </span><span class="s1">canNewFetchStrategyProvideMoreContent(</span><span class="s3">\n          </span><span class="s1">segment.fetchStrategy,</span><span class="s3">\n          </span><span class="s1">fetchStrategy</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">) {</span><span class="s3">\n        </span><span class="s1">// The cached segment contains dynamic holes, and was prefetched using a less specific strategy than the current one.</span><span class="s3">\n        </span><span class="s1">// This means we're in one of these cases:</span><span class="s3">\n        </span><span class="s1">//   - we have a static prefetch, and we're doing a runtime prefetch</span><span class="s3">\n        </span><span class="s1">//   - we have a static or runtime prefetch, and we're doing a Full prefetch (or a navigation).</span><span class="s3">\n        </span><span class="s1">// In either case, we need to include it in the request to get a more specific (or full) version.</span><span class="s3">\n        </span><span class="s1">spawnedSegment = pingFullSegmentRevalidation(</span><span class="s3">\n          </span><span class="s1">now,</span><span class="s3">\n          </span><span class="s1">task,</span><span class="s3">\n          </span><span class="s1">route,</span><span class="s3">\n          </span><span class="s1">segment,</span><span class="s3">\n          </span><span class="s1">tree,</span><span class="s3">\n          </span><span class="s1">fetchStrategy</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Pending:</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Rejected: {</span><span class="s3">\n      </span><span class="s1">// There's either another prefetch currently in progress, or the previous</span><span class="s3">\n      </span><span class="s1">// attempt failed. If the new strategy can provide more content, fetch it again.</span><span class="s3">\n      </span><span class="s1">if (</span><span class="s3">\n        </span><span class="s1">canNewFetchStrategyProvideMoreContent(</span><span class="s3">\n          </span><span class="s1">segment.fetchStrategy,</span><span class="s3">\n          </span><span class="s1">fetchStrategy</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">) {</span><span class="s3">\n        </span><span class="s1">spawnedSegment = pingFullSegmentRevalidation(</span><span class="s3">\n          </span><span class="s1">now,</span><span class="s3">\n          </span><span class="s1">task,</span><span class="s3">\n          </span><span class="s1">route,</span><span class="s3">\n          </span><span class="s1">segment,</span><span class="s3">\n          </span><span class="s1">tree,</span><span class="s3">\n          </span><span class="s1">fetchStrategy</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">default:</span><span class="s3">\n      </span><span class="s1">segment satisfies never</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">const requestTreeChildren: Record&lt;string, FlightRouterState&gt; = {}</span><span class="s3">\n  </span><span class="s1">if (tree.slots !== null) {</span><span class="s3">\n    </span><span class="s1">for (const parallelRouteKey in tree.slots) {</span><span class="s3">\n      </span><span class="s1">const childTree = tree.slots[parallelRouteKey]</span><span class="s3">\n      </span><span class="s1">requestTreeChildren[parallelRouteKey] =</span><span class="s3">\n        </span><span class="s1">pingRouteTreeAndIncludeDynamicData(</span><span class="s3">\n          </span><span class="s1">now,</span><span class="s3">\n          </span><span class="s1">task,</span><span class="s3">\n          </span><span class="s1">route,</span><span class="s3">\n          </span><span class="s1">childTree,</span><span class="s3">\n          </span><span class="s1">isInsideRefetchingParent || spawnedSegment !== null,</span><span class="s3">\n          </span><span class="s1">spawnedEntries,</span><span class="s3">\n          </span><span class="s1">fetchStrategy</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n\n  </span><span class="s1">if (spawnedSegment !== null) {</span><span class="s3">\n    </span><span class="s1">// Add the pending entry to the result map.</span><span class="s3">\n    </span><span class="s1">spawnedEntries.set(tree.cacheKey, spawnedSegment)</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n\n  </span><span class="s1">// Don't bother to add a refetch marker if one is already present in a parent.</span><span class="s3">\n  </span><span class="s1">const refetchMarker =</span><span class="s3">\n    </span><span class="s1">!isInsideRefetchingParent &amp;&amp; spawnedSegment !== null ? 'refetch' : null</span><span class="s3">\n\n  </span><span class="s1">const requestTree: FlightRouterState = [</span><span class="s3">\n    </span><span class="s1">tree.segment,</span><span class="s3">\n    </span><span class="s1">requestTreeChildren,</span><span class="s3">\n    </span><span class="s1">null,</span><span class="s3">\n    </span><span class="s1">refetchMarker,</span><span class="s3">\n    </span><span class="s1">tree.isRootLayout,</span><span class="s3">\n  </span><span class="s1">]</span><span class="s3">\n  </span><span class="s1">return requestTree</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function pingPerSegment(</span><span class="s3">\n  </span><span class="s1">now: number,</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">segment: SegmentCacheEntry,</span><span class="s3">\n  </span><span class="s1">routeKey: RouteCacheKey,</span><span class="s3">\n  </span><span class="s1">tree: RouteTree</span><span class="s3">\n</span><span class="s1">): void {</span><span class="s3">\n  </span><span class="s1">switch (segment.status) {</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Empty:</span><span class="s3">\n      </span><span class="s1">// Upgrade to Pending so we know there's already a request in progress</span><span class="s3">\n      </span><span class="s1">spawnPrefetchSubtask(</span><span class="s3">\n        </span><span class="s1">fetchSegmentOnCacheMiss(</span><span class="s3">\n          </span><span class="s1">route,</span><span class="s3">\n          </span><span class="s1">upgradeToPendingSegment(segment, FetchStrategy.PPR),</span><span class="s3">\n          </span><span class="s1">routeKey,</span><span class="s3">\n          </span><span class="s1">tree</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Pending: {</span><span class="s3">\n      </span><span class="s1">// There's already a request in progress. Depending on what kind of</span><span class="s3">\n      </span><span class="s1">// request it is, we may want to revalidate it.</span><span class="s3">\n      </span><span class="s1">switch (segment.fetchStrategy) {</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.PPR:</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.PPRRuntime:</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.Full:</span><span class="s3">\n          </span><span class="s1">// There's already a request in progress. Don't do anything.</span><span class="s3">\n          </span><span class="s1">break</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.LoadingBoundary:</span><span class="s3">\n          </span><span class="s1">// There's a pending request, but because it's using the old</span><span class="s3">\n          </span><span class="s1">// prefetching strategy, we can't be sure if it will be fulfilled by</span><span class="s3">\n          </span><span class="s1">// the response — it might be inside the loading boundary. Perform</span><span class="s3">\n          </span><span class="s1">// a revalidation, but because it's speculative, wait to do it at</span><span class="s3">\n          </span><span class="s1">// background priority.</span><span class="s3">\n          </span><span class="s1">if (background(task)) {</span><span class="s3">\n            </span><span class="s1">// TODO: Instead of speculatively revalidating, consider including</span><span class="s3">\n            </span><span class="s1">// `hasLoading` in the route tree prefetch response.</span><span class="s3">\n            </span><span class="s1">pingPPRSegmentRevalidation(</span><span class="s3">\n              </span><span class="s1">now,</span><span class="s3">\n              </span><span class="s1">task,</span><span class="s3">\n              </span><span class="s1">segment,</span><span class="s3">\n              </span><span class="s1">route,</span><span class="s3">\n              </span><span class="s1">routeKey,</span><span class="s3">\n              </span><span class="s1">tree</span><span class="s3">\n            </span><span class="s1">)</span><span class="s3">\n          </span><span class="s1">}</span><span class="s3">\n          </span><span class="s1">break</span><span class="s3">\n        </span><span class="s1">default:</span><span class="s3">\n          </span><span class="s1">segment.fetchStrategy satisfies never</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Rejected: {</span><span class="s3">\n      </span><span class="s1">// The existing entry in the cache was rejected. Depending on how it</span><span class="s3">\n      </span><span class="s1">// was originally fetched, we may or may not want to revalidate it.</span><span class="s3">\n      </span><span class="s1">switch (segment.fetchStrategy) {</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.PPR:</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.PPRRuntime:</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.Full:</span><span class="s3">\n          </span><span class="s1">// The previous attempt to fetch this entry failed. Don't attempt to</span><span class="s3">\n          </span><span class="s1">// fetch it again until the entry expires.</span><span class="s3">\n          </span><span class="s1">break</span><span class="s3">\n        </span><span class="s1">case FetchStrategy.LoadingBoundary:</span><span class="s3">\n          </span><span class="s1">// There's a rejected entry, but it was fetched using the loading</span><span class="s3">\n          </span><span class="s1">// boundary strategy. So the reason it wasn't returned by the server</span><span class="s3">\n          </span><span class="s1">// might just be because it was inside a loading boundary. Or because</span><span class="s3">\n          </span><span class="s1">// there was a dynamic rewrite. Revalidate it using the per-</span><span class="s3">\n          </span><span class="s1">// segment strategy.</span><span class="s3">\n          </span><span class="s1">//</span><span class="s3">\n          </span><span class="s1">// Because a rejected segment will definitely prevent the segment (and</span><span class="s3">\n          </span><span class="s1">// all of its children) from rendering, we perform this revalidation</span><span class="s3">\n          </span><span class="s1">// immediately instead of deferring it to a background task.</span><span class="s3">\n          </span><span class="s1">pingPPRSegmentRevalidation(now, task, segment, route, routeKey, tree)</span><span class="s3">\n          </span><span class="s1">break</span><span class="s3">\n        </span><span class="s1">default:</span><span class="s3">\n          </span><span class="s1">segment.fetchStrategy satisfies never</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Fulfilled:</span><span class="s3">\n      </span><span class="s1">// Segment is already cached. There's nothing left to prefetch.</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">default:</span><span class="s3">\n      </span><span class="s1">segment satisfies never</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n\n  </span><span class="s1">// Segments do not have dependent tasks, so once the prefetch is initiated,</span><span class="s3">\n  </span><span class="s1">// there's nothing else for us to do (except write the server data into the</span><span class="s3">\n  </span><span class="s1">// entry, which is handled by `fetchSegmentOnCacheMiss`).</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function pingPPRSegmentRevalidation(</span><span class="s3">\n  </span><span class="s1">now: number,</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">currentSegment: SegmentCacheEntry,</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">routeKey: RouteCacheKey,</span><span class="s3">\n  </span><span class="s1">tree: RouteTree</span><span class="s3">\n</span><span class="s1">): void {</span><span class="s3">\n  </span><span class="s1">const revalidatingSegment = readOrCreateRevalidatingSegmentEntry(</span><span class="s3">\n    </span><span class="s1">now,</span><span class="s3">\n    </span><span class="s1">currentSegment</span><span class="s3">\n  </span><span class="s1">)</span><span class="s3">\n  </span><span class="s1">switch (revalidatingSegment.status) {</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Empty:</span><span class="s3">\n      </span><span class="s1">// Spawn a prefetch request and upsert the segment into the cache</span><span class="s3">\n      </span><span class="s1">// upon completion.</span><span class="s3">\n      </span><span class="s1">upsertSegmentOnCompletion(</span><span class="s3">\n        </span><span class="s1">task,</span><span class="s3">\n        </span><span class="s1">route,</span><span class="s3">\n        </span><span class="s1">tree.cacheKey,</span><span class="s3">\n        </span><span class="s1">spawnPrefetchSubtask(</span><span class="s3">\n          </span><span class="s1">fetchSegmentOnCacheMiss(</span><span class="s3">\n            </span><span class="s1">route,</span><span class="s3">\n            </span><span class="s1">upgradeToPendingSegment(revalidatingSegment, FetchStrategy.PPR),</span><span class="s3">\n            </span><span class="s1">routeKey,</span><span class="s3">\n            </span><span class="s1">tree</span><span class="s3">\n          </span><span class="s1">)</span><span class="s3">\n        </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Pending:</span><span class="s3">\n      </span><span class="s1">// There's already a revalidation in progress.</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Fulfilled:</span><span class="s3">\n    </span><span class="s1">case EntryStatus.Rejected:</span><span class="s3">\n      </span><span class="s1">// A previous revalidation attempt finished, but we chose not to replace</span><span class="s3">\n      </span><span class="s1">// the existing entry in the cache. Don't try again until or unless the</span><span class="s3">\n      </span><span class="s1">// revalidation entry expires.</span><span class="s3">\n      </span><span class="s1">break</span><span class="s3">\n    </span><span class="s1">default:</span><span class="s3">\n      </span><span class="s1">revalidatingSegment satisfies never</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function pingFullSegmentRevalidation(</span><span class="s3">\n  </span><span class="s1">now: number,</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">currentSegment: SegmentCacheEntry,</span><span class="s3">\n  </span><span class="s1">tree: RouteTree,</span><span class="s3">\n  </span><span class="s1">fetchStrategy: FetchStrategy.Full | FetchStrategy.PPRRuntime</span><span class="s3">\n</span><span class="s1">): PendingSegmentCacheEntry | null {</span><span class="s3">\n  </span><span class="s1">const revalidatingSegment = readOrCreateRevalidatingSegmentEntry(</span><span class="s3">\n    </span><span class="s1">now,</span><span class="s3">\n    </span><span class="s1">currentSegment</span><span class="s3">\n  </span><span class="s1">)</span><span class="s3">\n  </span><span class="s1">if (revalidatingSegment.status === EntryStatus.Empty) {</span><span class="s3">\n    </span><span class="s1">// During a Full/PPRRuntime prefetch, a single dynamic request is made for all the</span><span class="s3">\n    </span><span class="s1">// segments that we need. So we don't initiate a request here directly. By</span><span class="s3">\n    </span><span class="s1">// returning a pending entry from this function, it signals to the caller</span><span class="s3">\n    </span><span class="s1">// that this segment should be included in the request that's sent to</span><span class="s3">\n    </span><span class="s1">// the server.</span><span class="s3">\n    </span><span class="s1">const pendingSegment = upgradeToPendingSegment(</span><span class="s3">\n      </span><span class="s1">revalidatingSegment,</span><span class="s3">\n      </span><span class="s1">fetchStrategy</span><span class="s3">\n    </span><span class="s1">)</span><span class="s3">\n    </span><span class="s1">upsertSegmentOnCompletion(</span><span class="s3">\n      </span><span class="s1">task,</span><span class="s3">\n      </span><span class="s1">route,</span><span class="s3">\n      </span><span class="s1">tree.cacheKey,</span><span class="s3">\n      </span><span class="s1">waitForSegmentCacheEntry(pendingSegment)</span><span class="s3">\n    </span><span class="s1">)</span><span class="s3">\n    </span><span class="s1">return pendingSegment</span><span class="s3">\n  </span><span class="s1">} else {</span><span class="s3">\n    </span><span class="s1">// There's already a revalidation in progress.</span><span class="s3">\n    </span><span class="s1">const nonEmptyRevalidatingSegment = revalidatingSegment</span><span class="s3">\n    </span><span class="s1">if (</span><span class="s3">\n      </span><span class="s1">canNewFetchStrategyProvideMoreContent(</span><span class="s3">\n        </span><span class="s1">nonEmptyRevalidatingSegment.fetchStrategy,</span><span class="s3">\n        </span><span class="s1">fetchStrategy</span><span class="s3">\n      </span><span class="s1">)</span><span class="s3">\n    </span><span class="s1">) {</span><span class="s3">\n      </span><span class="s1">// The existing revalidation was fetched using a less specific strategy.</span><span class="s3">\n      </span><span class="s1">// Reset it and start a new revalidation.</span><span class="s3">\n      </span><span class="s1">const emptySegment = resetRevalidatingSegmentEntry(</span><span class="s3">\n        </span><span class="s1">nonEmptyRevalidatingSegment</span><span class="s3">\n      </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">const pendingSegment = upgradeToPendingSegment(</span><span class="s3">\n        </span><span class="s1">emptySegment,</span><span class="s3">\n        </span><span class="s1">fetchStrategy</span><span class="s3">\n      </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">upsertSegmentOnCompletion(</span><span class="s3">\n        </span><span class="s1">task,</span><span class="s3">\n        </span><span class="s1">route,</span><span class="s3">\n        </span><span class="s1">tree.cacheKey,</span><span class="s3">\n        </span><span class="s1">waitForSegmentCacheEntry(pendingSegment)</span><span class="s3">\n      </span><span class="s1">)</span><span class="s3">\n      </span><span class="s1">return pendingSegment</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">switch (nonEmptyRevalidatingSegment.status) {</span><span class="s3">\n      </span><span class="s1">case EntryStatus.Pending:</span><span class="s3">\n        </span><span class="s1">// There's already an in-progress prefetch that includes this segment.</span><span class="s3">\n        </span><span class="s1">return null</span><span class="s3">\n      </span><span class="s1">case EntryStatus.Fulfilled:</span><span class="s3">\n      </span><span class="s1">case EntryStatus.Rejected:</span><span class="s3">\n        </span><span class="s1">// A previous revalidation attempt finished, but we chose not to replace</span><span class="s3">\n        </span><span class="s1">// the existing entry in the cache. Don't try again until or unless the</span><span class="s3">\n        </span><span class="s1">// revalidation entry expires.</span><span class="s3">\n        </span><span class="s1">return null</span><span class="s3">\n      </span><span class="s1">default:</span><span class="s3">\n        </span><span class="s1">nonEmptyRevalidatingSegment satisfies never</span><span class="s3">\n        </span><span class="s1">return null</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">const noop = () =&gt; {}</span><span class="s3">\n\n</span><span class="s1">function upsertSegmentOnCompletion(</span><span class="s3">\n  </span><span class="s1">task: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">cacheKey: SegmentCacheKey,</span><span class="s3">\n  </span><span class="s1">promise: Promise&lt;FulfilledSegmentCacheEntry | null&gt;</span><span class="s3">\n</span><span class="s1">) {</span><span class="s3">\n  </span><span class="s1">// Wait for a segment to finish loading, then upsert it into the cache</span><span class="s3">\n  </span><span class="s1">promise.then((fulfilled) =&gt; {</span><span class="s3">\n    </span><span class="s1">if (fulfilled !== null) {</span><span class="s3">\n      </span><span class="s1">// Received new data. Attempt to replace the existing entry in the cache.</span><span class="s3">\n      </span><span class="s1">const keypath = getSegmentKeypathForTask(task, route, cacheKey)</span><span class="s3">\n      </span><span class="s1">upsertSegmentEntry(Date.now(), keypath, fulfilled)</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}, noop)</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function doesCurrentSegmentMatchCachedSegment(</span><span class="s3">\n  </span><span class="s1">route: FulfilledRouteCacheEntry,</span><span class="s3">\n  </span><span class="s1">currentSegment: Segment,</span><span class="s3">\n  </span><span class="s1">cachedSegment: Segment</span><span class="s3">\n</span><span class="s1">): boolean {</span><span class="s3">\n  </span><span class="s1">if (cachedSegment === PAGE_SEGMENT_KEY) {</span><span class="s3">\n    </span><span class="s1">// In the FlightRouterState stored by the router, the page segment has the</span><span class="s3">\n    </span><span class="s1">// rendered search params appended to the name of the segment. In the</span><span class="s3">\n    </span><span class="s1">// prefetch cache, however, this is stored separately. So, when comparing</span><span class="s3">\n    </span><span class="s1">// the router's current FlightRouterState to the cached FlightRouterState,</span><span class="s3">\n    </span><span class="s1">// we need to make sure we compare both parts of the segment.</span><span class="s3">\n    </span><span class="s1">// TODO: This is not modeled clearly. We use the same type,</span><span class="s3">\n    </span><span class="s1">// FlightRouterState, for both the CacheNode tree _and_ the prefetch cache</span><span class="s3">\n    </span><span class="s1">// _and_ the server response format, when conceptually those are three</span><span class="s3">\n    </span><span class="s1">// different things and treated in different ways. We should encode more of</span><span class="s3">\n    </span><span class="s1">// this information into the type design so mistakes are less likely.</span><span class="s3">\n    </span><span class="s1">return (</span><span class="s3">\n      </span><span class="s1">currentSegment ===</span><span class="s3">\n      </span><span class="s1">addSearchParamsIfPageSegment(</span><span class="s3">\n        </span><span class="s1">PAGE_SEGMENT_KEY,</span><span class="s3">\n        </span><span class="s1">Object.fromEntries(new URLSearchParams(route.renderedSearch))</span><span class="s3">\n      </span><span class="s1">)</span><span class="s3">\n    </span><span class="s1">)</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">// Non-page segments are compared using the same function as the server</span><span class="s3">\n  </span><span class="s1">return matchSegment(cachedSegment, currentSegment)</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">// -----------------------------------------------------------------------------</span><span class="s3">\n</span><span class="s1">// The remainder of the module is a MinHeap implementation. Try not to put any</span><span class="s3">\n</span><span class="s1">// logic below here unless it's related to the heap algorithm. We can extract</span><span class="s3">\n</span><span class="s1">// this to a separate module if/when we need multiple kinds of heaps.</span><span class="s3">\n</span><span class="s1">// -----------------------------------------------------------------------------</span><span class="s3">\n\n</span><span class="s1">function compareQueuePriority(a: PrefetchTask, b: PrefetchTask) {</span><span class="s3">\n  </span><span class="s1">// Since the queue is a MinHeap, this should return a positive number if b is</span><span class="s3">\n  </span><span class="s1">// higher priority than a, and a negative number if a is higher priority</span><span class="s3">\n  </span><span class="s1">// than b.</span><span class="s3">\n\n  </span><span class="s1">// `priority` is an integer, where higher numbers are higher priority.</span><span class="s3">\n  </span><span class="s1">const priorityDiff = b.priority - a.priority</span><span class="s3">\n  </span><span class="s1">if (priorityDiff !== 0) {</span><span class="s3">\n    </span><span class="s1">return priorityDiff</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n\n  </span><span class="s1">// If the priority is the same, check which phase the prefetch is in — is it</span><span class="s3">\n  </span><span class="s1">// prefetching the route tree, or the segments? Route trees are prioritized.</span><span class="s3">\n  </span><span class="s1">const phaseDiff = b.phase - a.phase</span><span class="s3">\n  </span><span class="s1">if (phaseDiff !== 0) {</span><span class="s3">\n    </span><span class="s1">return phaseDiff</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n\n  </span><span class="s1">// Finally, check the insertion order. `sortId` is an incrementing counter</span><span class="s3">\n  </span><span class="s1">// assigned to prefetches. We want to process the newest prefetches first.</span><span class="s3">\n  </span><span class="s1">return b.sortId - a.sortId</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function heapPush(heap: Array&lt;PrefetchTask&gt;, node: PrefetchTask): void {</span><span class="s3">\n  </span><span class="s1">const index = heap.length</span><span class="s3">\n  </span><span class="s1">heap.push(node)</span><span class="s3">\n  </span><span class="s1">node._heapIndex = index</span><span class="s3">\n  </span><span class="s1">heapSiftUp(heap, node, index)</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function heapPeek(heap: Array&lt;PrefetchTask&gt;): PrefetchTask | null {</span><span class="s3">\n  </span><span class="s1">return heap.length === 0 ? null : heap[0]</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function heapPop(heap: Array&lt;PrefetchTask&gt;): PrefetchTask | null {</span><span class="s3">\n  </span><span class="s1">if (heap.length === 0) {</span><span class="s3">\n    </span><span class="s1">return null</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">const first = heap[0]</span><span class="s3">\n  </span><span class="s1">first._heapIndex = -1</span><span class="s3">\n  </span><span class="s1">const last = heap.pop() as PrefetchTask</span><span class="s3">\n  </span><span class="s1">if (last !== first) {</span><span class="s3">\n    </span><span class="s1">heap[0] = last</span><span class="s3">\n    </span><span class="s1">last._heapIndex = 0</span><span class="s3">\n    </span><span class="s1">heapSiftDown(heap, last, 0)</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">return first</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function heapDelete(heap: Array&lt;PrefetchTask&gt;, node: PrefetchTask): void {</span><span class="s3">\n  </span><span class="s1">const index = node._heapIndex</span><span class="s3">\n  </span><span class="s1">if (index !== -1) {</span><span class="s3">\n    </span><span class="s1">node._heapIndex = -1</span><span class="s3">\n    </span><span class="s1">if (heap.length !== 0) {</span><span class="s3">\n      </span><span class="s1">const last = heap.pop() as PrefetchTask</span><span class="s3">\n      </span><span class="s1">if (last !== node) {</span><span class="s3">\n        </span><span class="s1">heap[index] = last</span><span class="s3">\n        </span><span class="s1">last._heapIndex = index</span><span class="s3">\n        </span><span class="s1">heapSiftDown(heap, last, index)</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function heapResift(heap: Array&lt;PrefetchTask&gt;, node: PrefetchTask): void {</span><span class="s3">\n  </span><span class="s1">const index = node._heapIndex</span><span class="s3">\n  </span><span class="s1">if (index !== -1) {</span><span class="s3">\n    </span><span class="s1">if (index === 0) {</span><span class="s3">\n      </span><span class="s1">heapSiftDown(heap, node, 0)</span><span class="s3">\n    </span><span class="s1">} else {</span><span class="s3">\n      </span><span class="s1">const parentIndex = (index - 1) &gt;&gt;&gt; 1</span><span class="s3">\n      </span><span class="s1">const parent = heap[parentIndex]</span><span class="s3">\n      </span><span class="s1">if (compareQueuePriority(parent, node) &gt; 0) {</span><span class="s3">\n        </span><span class="s1">// The parent is larger. Sift up.</span><span class="s3">\n        </span><span class="s1">heapSiftUp(heap, node, index)</span><span class="s3">\n      </span><span class="s1">} else {</span><span class="s3">\n        </span><span class="s1">// The parent is smaller (or equal). Sift down.</span><span class="s3">\n        </span><span class="s1">heapSiftDown(heap, node, index)</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function heapSiftUp(</span><span class="s3">\n  </span><span class="s1">heap: Array&lt;PrefetchTask&gt;,</span><span class="s3">\n  </span><span class="s1">node: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">i: number</span><span class="s3">\n</span><span class="s1">): void {</span><span class="s3">\n  </span><span class="s1">let index = i</span><span class="s3">\n  </span><span class="s1">while (index &gt; 0) {</span><span class="s3">\n    </span><span class="s1">const parentIndex = (index - 1) &gt;&gt;&gt; 1</span><span class="s3">\n    </span><span class="s1">const parent = heap[parentIndex]</span><span class="s3">\n    </span><span class="s1">if (compareQueuePriority(parent, node) &gt; 0) {</span><span class="s3">\n      </span><span class="s1">// The parent is larger. Swap positions.</span><span class="s3">\n      </span><span class="s1">heap[parentIndex] = node</span><span class="s3">\n      </span><span class="s1">node._heapIndex = parentIndex</span><span class="s3">\n      </span><span class="s1">heap[index] = parent</span><span class="s3">\n      </span><span class="s1">parent._heapIndex = index</span><span class="s3">\n\n      </span><span class="s1">index = parentIndex</span><span class="s3">\n    </span><span class="s1">} else {</span><span class="s3">\n      </span><span class="s1">// The parent is smaller. Exit.</span><span class="s3">\n      </span><span class="s1">return</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n\n</span><span class="s1">function heapSiftDown(</span><span class="s3">\n  </span><span class="s1">heap: Array&lt;PrefetchTask&gt;,</span><span class="s3">\n  </span><span class="s1">node: PrefetchTask,</span><span class="s3">\n  </span><span class="s1">i: number</span><span class="s3">\n</span><span class="s1">): void {</span><span class="s3">\n  </span><span class="s1">let index = i</span><span class="s3">\n  </span><span class="s1">const length = heap.length</span><span class="s3">\n  </span><span class="s1">const halfLength = length &gt;&gt;&gt; 1</span><span class="s3">\n  </span><span class="s1">while (index &lt; halfLength) {</span><span class="s3">\n    </span><span class="s1">const leftIndex = (index + 1) * 2 - 1</span><span class="s3">\n    </span><span class="s1">const left = heap[leftIndex]</span><span class="s3">\n    </span><span class="s1">const rightIndex = leftIndex + 1</span><span class="s3">\n    </span><span class="s1">const right = heap[rightIndex]</span><span class="s3">\n\n    </span><span class="s1">// If the left or right node is smaller, swap with the smaller of those.</span><span class="s3">\n    </span><span class="s1">if (compareQueuePriority(left, node) &lt; 0) {</span><span class="s3">\n      </span><span class="s1">if (rightIndex &lt; length &amp;&amp; compareQueuePriority(right, left) &lt; 0) {</span><span class="s3">\n        </span><span class="s1">heap[index] = right</span><span class="s3">\n        </span><span class="s1">right._heapIndex = index</span><span class="s3">\n        </span><span class="s1">heap[rightIndex] = node</span><span class="s3">\n        </span><span class="s1">node._heapIndex = rightIndex</span><span class="s3">\n\n        </span><span class="s1">index = rightIndex</span><span class="s3">\n      </span><span class="s1">} else {</span><span class="s3">\n        </span><span class="s1">heap[index] = left</span><span class="s3">\n        </span><span class="s1">left._heapIndex = index</span><span class="s3">\n        </span><span class="s1">heap[leftIndex] = node</span><span class="s3">\n        </span><span class="s1">node._heapIndex = leftIndex</span><span class="s3">\n\n        </span><span class="s1">index = leftIndex</span><span class="s3">\n      </span><span class="s1">}</span><span class="s3">\n    </span><span class="s1">} else if (rightIndex &lt; length &amp;&amp; compareQueuePriority(right, node) &lt; 0) {</span><span class="s3">\n      </span><span class="s1">heap[index] = right</span><span class="s3">\n      </span><span class="s1">right._heapIndex = index</span><span class="s3">\n      </span><span class="s1">heap[rightIndex] = node</span><span class="s3">\n      </span><span class="s1">node._heapIndex = rightIndex</span><span class="s3">\n\n      </span><span class="s1">index = rightIndex</span><span class="s3">\n    </span><span class="s1">} else {</span><span class="s3">\n      </span><span class="s1">// Neither child is smaller. Exit.</span><span class="s3">\n      </span><span class="s1">return</span><span class="s3">\n    </span><span class="s1">}</span><span class="s3">\n  </span><span class="s1">}</span><span class="s3">\n</span><span class="s1">}</span><span class="s3">\n</span><span class="s1">&quot;</span><span class="s0">],</span><span class="s1">&quot;names&quot;</span><span class="s0">:[</span><span class="s1">&quot;cancelPrefetchTask&quot;</span><span class="s0">,</span><span class="s1">&quot;isPrefetchTaskDirty&quot;</span><span class="s0">,</span><span class="s1">&quot;pingPrefetchTask&quot;</span><span class="s0">,</span><span class="s1">&quot;reschedulePrefetchTask&quot;</span><span class="s0">,</span><span class="s1">&quot;schedulePrefetchTask&quot;</span><span class="s0">,</span><span class="s1">&quot;scheduleMicrotask&quot;</span><span class="s0">,</span><span class="s1">&quot;queueMicrotask&quot;</span><span class="s0">,</span><span class="s1">&quot;fn&quot;</span><span class="s0">,</span><span class="s1">&quot;Promise&quot;</span><span class="s0">,</span><span class="s1">&quot;resolve&quot;</span><span class="s0">,</span><span class="s1">&quot;then&quot;</span><span class="s0">,</span><span class="s1">&quot;catch&quot;</span><span class="s0">,</span><span class="s1">&quot;error&quot;</span><span class="s0">,</span><span class="s1">&quot;setTimeout&quot;</span><span class="s0">,</span><span class="s1">&quot;taskHeap&quot;</span><span class="s0">,</span><span class="s1">&quot;inProgressRequests&quot;</span><span class="s0">,</span><span class="s1">&quot;sortIdCounter&quot;</span><span class="s0">,</span><span class="s1">&quot;didScheduleMicrotask&quot;</span><span class="s0">,</span><span class="s1">&quot;mostRecentlyHoveredLink&quot;</span><span class="s0">,</span><span class="s1">&quot;key&quot;</span><span class="s0">,</span><span class="s1">&quot;treeAtTimeOfPrefetch&quot;</span><span class="s0">,</span><span class="s1">&quot;fetchStrategy&quot;</span><span class="s0">,</span><span class="s1">&quot;priority&quot;</span><span class="s0">,</span><span class="s1">&quot;onInvalidate&quot;</span><span class="s0">,</span><span class="s1">&quot;task&quot;</span><span class="s0">,</span><span class="s1">&quot;cacheVersion&quot;</span><span class="s0">,</span><span class="s1">&quot;getCurrentCacheVersion&quot;</span><span class="s0">,</span><span class="s1">&quot;phase&quot;</span><span class="s0">,</span><span class="s1">&quot;hasBackgroundWork&quot;</span><span class="s0">,</span><span class="s1">&quot;sortId&quot;</span><span class="s0">,</span><span class="s1">&quot;isCanceled&quot;</span><span class="s0">,</span><span class="s1">&quot;_heapIndex&quot;</span><span class="s0">,</span><span class="s1">&quot;trackMostRecentlyHoveredLink&quot;</span><span class="s0">,</span><span class="s1">&quot;heapPush&quot;</span><span class="s0">,</span><span class="s1">&quot;ensureWorkIsScheduled&quot;</span><span class="s0">,</span><span class="s1">&quot;heapDelete&quot;</span><span class="s0">,</span><span class="s1">&quot;PrefetchPriority&quot;</span><span class="s0">,</span><span class="s1">&quot;Intent&quot;</span><span class="s0">,</span><span class="s1">&quot;heapResift&quot;</span><span class="s0">,</span><span class="s1">&quot;nextUrl&quot;</span><span class="s0">,</span><span class="s1">&quot;tree&quot;</span><span class="s0">,</span><span class="s1">&quot;currentCacheVersion&quot;</span><span class="s0">,</span><span class="s1">&quot;Background&quot;</span><span class="s0">,</span><span class="s1">&quot;Default&quot;</span><span class="s0">,</span><span class="s1">&quot;processQueueInMicrotask&quot;</span><span class="s0">,</span><span class="s1">&quot;hasNetworkBandwidth&quot;</span><span class="s0">,</span><span class="s1">&quot;spawnPrefetchSubtask&quot;</span><span class="s0">,</span><span class="s1">&quot;prefetchSubtask&quot;</span><span class="s0">,</span><span class="s1">&quot;result&quot;</span><span class="s0">,</span><span class="s1">&quot;onPrefetchConnectionClosed&quot;</span><span class="s0">,</span><span class="s1">&quot;closed&quot;</span><span class="s0">,</span><span class="s1">&quot;value&quot;</span><span class="s0">,</span><span class="s1">&quot;now&quot;</span><span class="s0">,</span><span class="s1">&quot;Date&quot;</span><span class="s0">,</span><span class="s1">&quot;heapPeek&quot;</span><span class="s0">,</span><span class="s1">&quot;route&quot;</span><span class="s0">,</span><span class="s1">&quot;readOrCreateRouteCacheEntry&quot;</span><span class="s0">,</span><span class="s1">&quot;exitStatus&quot;</span><span class="s0">,</span><span class="s1">&quot;pingRootRouteTree&quot;</span><span class="s0">,</span><span class="s1">&quot;heapPop&quot;</span><span class="s0">,</span><span class="s1">&quot;background&quot;</span><span class="s0">,</span><span class="s1">&quot;status&quot;</span><span class="s0">,</span><span class="s1">&quot;EntryStatus&quot;</span><span class="s0">,</span><span class="s1">&quot;Empty&quot;</span><span class="s0">,</span><span class="s1">&quot;fetchRouteOnCacheMiss&quot;</span><span class="s0">,</span><span class="s1">&quot;staleAt&quot;</span><span class="s0">,</span><span class="s1">&quot;Pending&quot;</span><span class="s0">,</span><span class="s1">&quot;blockedTasks&quot;</span><span class="s0">,</span><span class="s1">&quot;Set&quot;</span><span class="s0">,</span><span class="s1">&quot;add&quot;</span><span class="s0">,</span><span class="s1">&quot;Rejected&quot;</span><span class="s0">,</span><span class="s1">&quot;Fulfilled&quot;</span><span class="s0">,</span><span class="s1">&quot;FetchStrategy&quot;</span><span class="s0">,</span><span class="s1">&quot;PPR&quot;</span><span class="s0">,</span><span class="s1">&quot;isPPREnabled&quot;</span><span class="s0">,</span><span class="s1">&quot;LoadingBoundary&quot;</span><span class="s0">,</span><span class="s1">&quot;pingPPRRouteTree&quot;</span><span class="s0">,</span><span class="s1">&quot;Full&quot;</span><span class="s0">,</span><span class="s1">&quot;PPRRuntime&quot;</span><span class="s0">,</span><span class="s1">&quot;spawnedEntries&quot;</span><span class="s0">,</span><span class="s1">&quot;Map&quot;</span><span class="s0">,</span><span class="s1">&quot;dynamicRequestTree&quot;</span><span class="s0">,</span><span class="s1">&quot;diffRouteTreeAgainstCurrent&quot;</span><span class="s0">,</span><span class="s1">&quot;needsDynamicRequest&quot;</span><span class="s0">,</span><span class="s1">&quot;size&quot;</span><span class="s0">,</span><span class="s1">&quot;isHeadPartial&quot;</span><span class="s0">,</span><span class="s1">&quot;TODO_metadataStatus&quot;</span><span class="s0">,</span><span class="s1">&quot;fetchSegmentPrefetchesUsingDynamicRequest&quot;</span><span class="s0">,</span><span class="s1">&quot;segment&quot;</span><span class="s0">,</span><span class="s1">&quot;readOrCreateSegmentCacheEntry&quot;</span><span class="s0">,</span><span class="s1">&quot;cacheKey&quot;</span><span class="s0">,</span><span class="s1">&quot;pingPerSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;slots&quot;</span><span class="s0">,</span><span class="s1">&quot;parallelRouteKey&quot;</span><span class="s0">,</span><span class="s1">&quot;childTree&quot;</span><span class="s0">,</span><span class="s1">&quot;childExitStatus&quot;</span><span class="s0">,</span><span class="s1">&quot;oldTree&quot;</span><span class="s0">,</span><span class="s1">&quot;newTree&quot;</span><span class="s0">,</span><span class="s1">&quot;oldTreeChildren&quot;</span><span class="s0">,</span><span class="s1">&quot;newTreeChildren&quot;</span><span class="s0">,</span><span class="s1">&quot;requestTreeChildren&quot;</span><span class="s0">,</span><span class="s1">&quot;newTreeChild&quot;</span><span class="s0">,</span><span class="s1">&quot;newTreeChildSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;oldTreeChild&quot;</span><span class="s0">,</span><span class="s1">&quot;oldTreeChildSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;undefined&quot;</span><span class="s0">,</span><span class="s1">&quot;doesCurrentSegmentMatchCachedSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;requestTreeChild&quot;</span><span class="s0">,</span><span class="s1">&quot;subtreeHasLoadingBoundary&quot;</span><span class="s0">,</span><span class="s1">&quot;hasLoadingBoundary&quot;</span><span class="s0">,</span><span class="s1">&quot;HasLoadingBoundary&quot;</span><span class="s0">,</span><span class="s1">&quot;SubtreeHasNoLoadingBoundary&quot;</span><span class="s0">,</span><span class="s1">&quot;pingPPRDisabledRouteTreeUpToLoadingBoundary&quot;</span><span class="s0">,</span><span class="s1">&quot;convertRouteTreeToFlightRouterState&quot;</span><span class="s0">,</span><span class="s1">&quot;pingRouteTreeAndIncludeDynamicData&quot;</span><span class="s0">,</span><span class="s1">&quot;requestTree&quot;</span><span class="s0">,</span><span class="s1">&quot;isRootLayout&quot;</span><span class="s0">,</span><span class="s1">&quot;refetchMarkerContext&quot;</span><span class="s0">,</span><span class="s1">&quot;refetchMarker&quot;</span><span class="s0">,</span><span class="s1">&quot;set&quot;</span><span class="s0">,</span><span class="s1">&quot;upgradeToPendingSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;segmentHasLoadingBoundary&quot;</span><span class="s0">,</span><span class="s1">&quot;SegmentHasLoadingBoundary&quot;</span><span class="s0">,</span><span class="s1">&quot;isInsideRefetchingParent&quot;</span><span class="s0">,</span><span class="s1">&quot;spawnedSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;isPartial&quot;</span><span class="s0">,</span><span class="s1">&quot;canNewFetchStrategyProvideMoreContent&quot;</span><span class="s0">,</span><span class="s1">&quot;pingFullSegmentRevalidation&quot;</span><span class="s0">,</span><span class="s1">&quot;routeKey&quot;</span><span class="s0">,</span><span class="s1">&quot;fetchSegmentOnCacheMiss&quot;</span><span class="s0">,</span><span class="s1">&quot;pingPPRSegmentRevalidation&quot;</span><span class="s0">,</span><span class="s1">&quot;currentSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;revalidatingSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;readOrCreateRevalidatingSegmentEntry&quot;</span><span class="s0">,</span><span class="s1">&quot;upsertSegmentOnCompletion&quot;</span><span class="s0">,</span><span class="s1">&quot;pendingSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;waitForSegmentCacheEntry&quot;</span><span class="s0">,</span><span class="s1">&quot;nonEmptyRevalidatingSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;emptySegment&quot;</span><span class="s0">,</span><span class="s1">&quot;resetRevalidatingSegmentEntry&quot;</span><span class="s0">,</span><span class="s1">&quot;noop&quot;</span><span class="s0">,</span><span class="s1">&quot;promise&quot;</span><span class="s0">,</span><span class="s1">&quot;fulfilled&quot;</span><span class="s0">,</span><span class="s1">&quot;keypath&quot;</span><span class="s0">,</span><span class="s1">&quot;getSegmentKeypathForTask&quot;</span><span class="s0">,</span><span class="s1">&quot;upsertSegmentEntry&quot;</span><span class="s0">,</span><span class="s1">&quot;cachedSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;PAGE_SEGMENT_KEY&quot;</span><span class="s0">,</span><span class="s1">&quot;addSearchParamsIfPageSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;Object&quot;</span><span class="s0">,</span><span class="s1">&quot;fromEntries&quot;</span><span class="s0">,</span><span class="s1">&quot;URLSearchParams&quot;</span><span class="s0">,</span><span class="s1">&quot;renderedSearch&quot;</span><span class="s0">,</span><span class="s1">&quot;matchSegment&quot;</span><span class="s0">,</span><span class="s1">&quot;compareQueuePriority&quot;</span><span class="s0">,</span><span class="s1">&quot;a&quot;</span><span class="s0">,</span><span class="s1">&quot;b&quot;</span><span class="s0">,</span><span class="s1">&quot;priorityDiff&quot;</span><span class="s0">,</span><span class="s1">&quot;phaseDiff&quot;</span><span class="s0">,</span><span class="s1">&quot;heap&quot;</span><span class="s0">,</span><span class="s1">&quot;node&quot;</span><span class="s0">,</span><span class="s1">&quot;index&quot;</span><span class="s0">,</span><span class="s1">&quot;length&quot;</span><span class="s0">,</span><span class="s1">&quot;push&quot;</span><span class="s0">,</span><span class="s1">&quot;heapSiftUp&quot;</span><span class="s0">,</span><span class="s1">&quot;first&quot;</span><span class="s0">,</span><span class="s1">&quot;last&quot;</span><span class="s0">,</span><span class="s1">&quot;pop&quot;</span><span class="s0">,</span><span class="s1">&quot;heapSiftDown&quot;</span><span class="s0">,</span><span class="s1">&quot;parentIndex&quot;</span><span class="s0">,</span><span class="s1">&quot;parent&quot;</span><span class="s0">,</span><span class="s1">&quot;i&quot;</span><span class="s0">,</span><span class="s1">&quot;halfLength&quot;</span><span class="s0">,</span><span class="s1">&quot;leftIndex&quot;</span><span class="s0">,</span><span class="s1">&quot;left&quot;</span><span class="s0">,</span><span class="s1">&quot;rightIndex&quot;</span><span class="s0">,</span><span class="s1">&quot;right&quot;</span><span class="s0">],</span><span class="s1">&quot;mappings&quot;</span><span class="s0">:</span><span class="s1">&quot;;;;;;;;;;;;;;;;;;;IAyPgBA,kBAAkB;eAAlBA;;IAiDAC,mBAAmB;eAAnBA;;IAkHAC,gBAAgB;eAAhBA;;IAzJAC,sBAAsB;eAAtBA;;IAhDAC,oBAAoB;eAApBA;;;uBA9MmB;+BACN;uBAsBtB;8BAOA;yBAIA;AAGP,MAAMC,oBACJ,OAAOC,mBAAmB,aACtBA,iBACA,CAACC,KACCC,QAAQC,OAAO,GACZC,IAAI,CAACH,IACLI,KAAK,CAAC,CAACC,QACNC,WAAW;YACT,MAAMD;QACR;AAsIZ,MAAME,WAAgC,EAAE;AAExC,IAAIC,qBAAqB;AAEzB,IAAIC,gBAAgB;AACpB,IAAIC,uBAAuB;AAE3B,8EAA8E;AAC9E,0EAA0E;AAC1E,+EAA+E;AAC/E,IAAIC,0BAA+C;AAgB5C,SAASd,qBACde,GAAkB,EAClBC,oBAAuC,EACvCC,aAAwC,EACxCC,QAA0B,EAC1BC,YAAiC;IAEjC,4BAA4B;IAC5B,MAAMC,OAAqB;QACzBL;QACAC;QACAK,cAAcC,IAAAA,oCAAsB;QACpCJ;QACAK,KAAK;QACLC,mBAAmB;QACnBP;QACAQ,QAAQb;QACRc,YAAY;QACZP;QACAQ,YAAY,CAAC;IACf;IAEAC,6BAA6BR;IAE7BS,SAASnB,UAAUU;IAEnB,+CAA+C;IAC/C,EAAE;IACF,yEAAyE;IACzE,yEAAyE;IACzE,2EAA2E;IAC3E,2EAA2E;IAC3E,qBAAqB;IACrBU;IAEA,OAAOV;AACT;AAEO,SAASxB,mBAAmBwB,IAAkB;IACnD,0EAA0E;IAC1E,wBAAwB;IACxB,EAAE;IACF,2EAA2E;IAC3E,wEAAwE;IACxEA,KAAKM,UAAU,GAAG;IAClBK,WAAWrB,UAAUU;AACvB;AAEO,SAASrB,uBACdqB,IAAkB,EAClBJ,oBAAuC,EACvCC,aAAwC,EACxCC,QAA0B;IAE1B,wEAAwE;IACxE,0EAA0E;IAC1E,mDAAmD;IACnD,EAAE;IACF,sEAAsE;IACtE,qBAAqB;IAErB,0DAA0D;IAC1DE,KAAKM,UAAU,GAAG;IAClBN,KAAKG,KAAK;IAEV,uEAAuE;IACvE,yDAAyD;IACzDH,KAAKK,MAAM,GAAGb;IACdQ,KAAKF,QAAQ,GACX,+DAA+D;IAC/D,8DAA8D;IAC9DE,SAASN,0BAA0BkB,8BAAgB,CAACC,MAAM,GAAGf;IAE/DE,KAAKJ,oBAAoB,GAAGA;IAC5BI,KAAKH,aAAa,GAAGA;IAErBW,6BAA6BR;IAE7B,IAAIA,KAAKO,UAAU,KAAK,CAAC,GAAG;QAC1B,oCAAoC;QACpCO,WAAWxB,UAAUU;IACvB,OAAO;QACLS,SAASnB,UAAUU;IACrB;IACAU;AACF;AAEO,SAASjC,oBACduB,IAAkB,EAClBe,OAAsB,EACtBC,IAAuB;IAEvB,uEAAuE;IACvE,uEAAuE;IACvE,2EAA2E;IAC3E,uEAAuE;IACvE,2BAA2B;IAC3B,MAAMC,sBAAsBf,IAAAA,oCAAsB;IAClD,OACEF,KAAKC,YAAY,KAAKgB,uBACtBjB,KAAKJ,oBAAoB,KAAKoB,QAC9BhB,KAAKL,GAAG,CAACoB,OAAO,KAAKA;AAEzB;AAEA,SAASP,6BAA6BR,IAAkB;IACtD,2EAA2E;IAC3E,uEAAuE;IACvE,IACEA,KAAKF,QAAQ,KAAKc,8BAAgB,CAACC,MAAM,IACzCb,SAASN,yBACT;QACA,IAAIA,4BAA4B,MAAM;YACpC,+DAA+D;YAC/D,IAAIA,wBAAwBI,QAAQ,KAAKc,8BAAgB,CAACM,UAAU,EAAE;gBACpExB,wBAAwBI,QAAQ,GAAGc,8BAAgB,CAACO,OAAO;gBAC3DL,WAAWxB,UAAUI;YACvB;QACF;QACAA,0BAA0BM;IAC5B;AACF;AAEA,SAASU;IACP,IAAIjB,sBAAsB;QACxB,gDAAgD;QAChD;IACF;IACAA,uBAAuB;IACvBZ,kBAAkBuC;AACpB;AAEA;;;;;CAKC,GACD,SAASC,oBAAoBrB,IAAkB;IAC7C,yEAAyE;IACzE,wEAAwE;IACxE,2EAA2E;IAC3E,sBAAsB;IAEtB,2EAA2E;IAE3E,IAAIA,KAAKF,QAAQ,KAAKc,8BAAgB,CAACC,MAAM,EAAE;QAC7C,yEAAyE;QACzE,EAAE;QACF,sEAAsE;QACtE,qCAAqC;QACrC,EAAE;QACF,4EAA4E;QAC5E,0EAA0E;QAC1E,iEAAiE;QACjE,OAAOtB,qBAAqB;IAC9B;IAEA,gEAAgE;IAChE,OAAOA,qBAAqB;AAC9B;AAEA,SAAS+B,qBACPC,eAAyD;IAEzD,sEAAsE;IACtE,0EAA0E;IAC1E,mCAAmC;IACnC,EAAE;IACF,wEAAwE;IACxE,2EAA2E;IAC3E,yEAAyE;IACzE,2EAA2E;IAC3E,kDAAkD;IAClDhC;IACA,OAAOgC,gBAAgBrC,IAAI,CAAC,CAACsC;QAC3B,IAAIA,WAAW,MAAM;YACnB,iEAAiE;YACjE,mDAAmD;YACnDC;YACA,OAAO;QACT;QACA,qEAAqE;QACrED,OAAOE,MAAM,CAACxC,IAAI,CAACuC;QACnB,OAAOD,OAAOG,KAAK;IACrB;AACF;AAEA,SAASF;IACPlC;IAEA,qEAAqE;IACrE,oBAAoB;IACpBmB;AACF;AAOO,SAAShC,iBAAiBsB,IAAkB;IACjD,yEAAyE;IACzE,IACE,kCAAkC;IAClCA,KAAKM,UAAU,IACf,uCAAuC;IACvCN,KAAKO,UAAU,KAAK,CAAC,GACrB;QACA;IACF;IACA,kCAAkC;IAClCE,SAASnB,UAAUU;IACnBU;AACF;AAEA,SAASU;IACP3B,uBAAuB;IAEvB,0EAA0E;IAC1E,4EAA4E;IAC5E,wDAAwD;IACxD,MAAMmC,MAAMC,KAAKD,GAAG;IAEpB,gEAAgE;IAChE,IAAI5B,OAAO8B,SAASxC;IACpB,MAAOU,SAAS,QAAQqB,oBAAoBrB,MAAO;QACjDA,KAAKC,YAAY,GAAGC,IAAAA,oCAAsB;QAE1C,MAAM6B,QAAQC,IAAAA,kCAA2B,EAACJ,KAAK5B;QAC/C,MAAMiC,aAAaC,kBAAkBN,KAAK5B,MAAM+B;QAEhD,0EAA0E;QAC1E,4BAA4B;QAC5B,MAAM3B,oBAAoBJ,KAAKI,iBAAiB;QAChDJ,KAAKI,iBAAiB,GAAG;QAEzB,OAAQ6B;YACN;gBACE,oEAAoE;gBACpE,sDAAsD;gBACtD;YACF;gBACE,iEAAiE;gBACjE,4DAA4D;gBAC5DE,QAAQ7C;gBACR,4BAA4B;gBAC5BU,OAAO8B,SAASxC;gBAChB;YACF;gBACE,IAAIU,KAAKG,KAAK,QAA8B;oBAC1C,8DAA8D;oBAC9D,gBAAgB;oBAChBH,KAAKG,KAAK;oBACVW,WAAWxB,UAAUU;gBACvB,OAAO,IAAII,mBAAmB;oBAC5B,mEAAmE;oBACnE,0BAA0B;oBAC1BJ,KAAKF,QAAQ,GAAGc,8BAAgB,CAACM,UAAU;oBAC3CJ,WAAWxB,UAAUU;gBACvB,OAAO;oBACL,uDAAuD;oBACvDmC,QAAQ7C;gBACV;gBACAU,OAAO8B,SAASxC;gBAChB;YACF;gBACE2C;QACJ;IACF;AACF;AAEA;;;;;;;;;CASC,GACD,SAASG,WAAWpC,IAAkB;IACpC,IAAIA,KAAKF,QAAQ,KAAKc,8BAAgB,CAACM,UAAU,EAAE;QACjD,OAAO;IACT;IACAlB,KAAKI,iBAAiB,GAAG;IACzB,OAAO;AACT;AAEA,SAAS8B,kBACPN,GAAW,EACX5B,IAAkB,EAClB+B,KAAsB;IAEtB,OAAQA,MAAMM,MAAM;QAClB,KAAKC,kBAAW,CAACC,KAAK;YAAE;gBACtB,uEAAuE;gBACvE,sEAAsE;gBACtE,wBAAwB;gBAExB,wEAAwE;gBACxE,uEAAuE;gBACvE,oBAAoB;gBACpB,EAAE;gBACF,wCAAwC;gBACxC,iDAAiD;gBACjD,sDAAsD;gBACtD,wEAAwE;gBACxE,EAAE;gBACF,oCAAoC;gBACpCjB,qBAAqBkB,IAAAA,4BAAqB,EAACT,OAAO/B;gBAElD,yEAAyE;gBACzE,wEAAwE;gBACxE,0EAA0E;gBAC1E,mBAAmB;gBACnB,0EAA0E;gBAC1E,oBAAoB;gBACpB+B,MAAMU,OAAO,GAAGb,MAAM,KAAK;gBAE3B,sEAAsE;gBACtEG,MAAMM,MAAM,GAAGC,kBAAW,CAACI,OAAO;YAElC,gDAAgD;YAClD;QACA,KAAKJ,kBAAW,CAACI,OAAO;YAAE;gBACxB,yEAAyE;gBACzE,uEAAuE;gBACvE,4CAA4C;gBAC5C,MAAMC,eAAeZ,MAAMY,YAAY;gBACvC,IAAIA,iBAAiB,MAAM;oBACzBZ,MAAMY,YAAY,GAAG,IAAIC,IAAI;wBAAC5C;qBAAK;gBACrC,OAAO;oBACL2C,aAAaE,GAAG,CAAC7C;gBACnB;gBACA;YACF;QACA,KAAKsC,kBAAW,CAACQ,QAAQ;YAAE;gBACzB,6CAA6C;gBAC7C;YACF;QACA,KAAKR,kBAAW,CAACS,SAAS;YAAE;gBAC1B,IAAI/C,KAAKG,KAAK,QAA6B;oBACzC,sEAAsE;oBACtE;gBACF;gBACA,wCAAwC;gBACxC,IAAI,CAACkB,oBAAoBrB,OAAO;oBAC9B,0DAA0D;oBAC1D;gBACF;gBACA,MAAMgB,OAAOe,MAAMf,IAAI;gBAEvB,qEAAqE;gBACrE,+FAA+F;gBAC/F,uFAAuF;gBACvF,+CAA+C;gBAC/C,MAAMnB,gBACJG,KAAKH,aAAa,KAAKmD,2BAAa,CAACC,GAAG,GACpClB,MAAMmB,YAAY,GAChBF,2BAAa,CAACC,GAAG,GACjBD,2BAAa,CAACG,eAAe,GAC/BnD,KAAKH,aAAa;gBAExB,OAAQA;oBACN,KAAKmD,2BAAa,CAACC,GAAG;wBACpB,mEAAmE;wBACnE,qEAAqE;wBACrE,iDAAiD;wBACjD,OAAOG,iBAAiBxB,KAAK5B,MAAM+B,OAAOf;oBAC5C,KAAKgC,2BAAa,CAACK,IAAI;oBACvB,KAAKL,2BAAa,CAACM,UAAU;oBAC7B,KAAKN,2BAAa,CAACG,eAAe;wBAAE;4BAClC,6DAA6D;4BAC7D,MAAMI,iBAAiB,IAAIC;4BAI3B,MAAMC,qBAAqBC,4BACzB9B,KACA5B,MACA+B,OACA/B,KAAKJ,oBAAoB,EACzBoB,MACAuC,gBACA1D;4BAGF,IAAI8D,sBAAsBJ,eAAeK,IAAI,GAAG;4BAEhD,IACE,CAACD,uBACD5B,MAAM8B,aAAa,IACnB9B,MAAM+B,mBAAmB,KAAKxB,kBAAW,CAACC,KAAK,EAC/C;gCACA,oEAAoE;gCACpE,kEAAkE;gCAClE,gEAAgE;gCAChE,2BAA2B;gCAC3B,mEAAmE;gCACnE,8DAA8D;gCAC9D,wDAAwD;gCACxD,oEAAoE;gCACpE,gEAAgE;gCAChE,+DAA+D;gCAC/D,kEAAkE;gCAClE,+DAA+D;gCAC/D,kEAAkE;gCAClE,0DAA0D;gCAC1D,yCAAyC;gCACzCR,MAAM+B,mBAAmB,GAAGxB,kBAAW,CAACS,SAAS;gCACjDY,sBAAsB;gCACtB,uDAAuD;gCACvDF,kBAAkB,CAAC,EAAE,GAAG;gCACxB,iEAAiE;gCACjE,wBAAwB;gCACxBA,kBAAkB,CAAC,EAAE,GAAG,CAAC;4BAC3B;4BAEA,IAAIE,qBAAqB;gCACvB,iEAAiE;gCACjE,aAAa;gCACbrC,qBACEyC,IAAAA,gDAAyC,EACvC/D,MACA+B,OACAlC,eACA4D,oBACAF;4BAGN;4BACA;wBACF;oBACA;wBACE1D;gBACJ;gBACA;YACF;QACA;YAAS;gBACPkC;YACF;IACF;IACA;AACF;AAEA,SAASqB,iBACPxB,GAAW,EACX5B,IAAkB,EAClB+B,KAA+B,EAC/Bf,IAAe;IAEf,MAAMgD,UAAUC,IAAAA,oCAA6B,EAACrC,KAAK5B,MAAM+B,OAAOf,KAAKkD,QAAQ;IAC7EC,eAAevC,KAAK5B,MAAM+B,OAAOiC,SAAShE,KAAKL,GAAG,EAAEqB;IACpD,IAAIA,KAAKoD,KAAK,KAAK,MAAM;QACvB,IAAI,CAAC/C,oBAAoBrB,OAAO;YAC9B,0DAA0D;YAC1D;QACF;QACA,iCAAiC;QACjC,IAAK,MAAMqE,oBAAoBrD,KAAKoD,KAAK,CAAE;YACzC,MAAME,YAAYtD,KAAKoD,KAAK,CAACC,iBAAiB;YAC9C,MAAME,kBAAkBnB,iBAAiBxB,KAAK5B,MAAM+B,OAAOuC;YAC3D,IAAIC,uBAAuD;gBACzD,mCAAmC;gBACnC;YACF;QACF;IACF;IACA,+DAA+D;IAC/D;AACF;AAEA,SAASb,4BACP9B,GAAW,EACX5B,IAAkB,EAClB+B,KAA+B,EAC/ByC,OAA0B,EAC1BC,OAAkB,EAClBlB,cAAqD,EACrD1D,aAGiC;IAEjC,kEAAkE;IAClE,uEAAuE;IACvE,4EAA4E;IAC5E,0BAA0B;IAC1B,uEAAuE;IACvE,sEAAsE;IACtE,yEAAyE;IACzE,2EAA2E;IAC3E,yBAAyB;IACzB,MAAM6E,kBAAkBF,OAAO,CAAC,EAAE;IAClC,MAAMG,kBAAkBF,QAAQL,KAAK;IACrC,IAAIQ,sBAAyD,CAAC;IAC9D,IAAID,oBAAoB,MAAM;QAC5B,IAAK,MAAMN,oBAAoBM,gBAAiB;YAC9C,MAAME,eAAeF,eAAe,CAACN,iBAAiB;YACtD,MAAMS,sBAAsBD,aAAab,OAAO;YAChD,MAAMe,eACJL,eAAe,CAACL,iBAAiB;YACnC,MAAMW,sBACJD,gCAAAA,YAAc,CAAC,EAAE;YACnB,IACEC,wBAAwBC,aACxBC,qCACEnD,OACA+C,qBACAE,sBAEF;gBACA,sEAAsE;gBACtE,MAAMG,mBAAmBzB,4BACvB9B,KACA5B,MACA+B,OACAgD,cACAF,cACAtB,gBACA1D;gBAEF+E,mBAAmB,CAACP,iBAAiB,GAAGc;YAC1C,OAAO;gBACL,kEAAkE;gBAClE,kEAAkE;gBAClE,mBAAmB;gBACnB,OAAQtF;oBACN,KAAKmD,2BAAa,CAACG,eAAe;wBAAE;4BAClC,+DAA+D;4BAC/D,oEAAoE;4BACpE,mEAAmE;4BACnE,YAAY;4BACZ,EAAE;4BACF,2DAA2D;4BAC3D,+DAA+D;4BAC/D,EAAE;4BACF,+DAA+D;4BAC/D,8DAA8D;4BAC9D,kEAAkE;4BAClE,2BAA2B;4BAC3B,MAAMiC,4BACJP,aAAaQ,kBAAkB,KAC/BC,yBAAkB,CAACC,2BAA2B;4BAChD,MAAMJ,mBAAmBC,4BACrBI,4CACE5D,KACA5B,MACA+B,OACA8C,cACA,MACAtB,kBAGFkC,IAAAA,0CAAmC,EAACZ;4BACxCD,mBAAmB,CAACP,iBAAiB,GAAGc;4BACxC;wBACF;oBACA,KAAKnC,2BAAa,CAACM,UAAU;wBAAE;4BAC7B,oEAAoE;4BACpE,iCAAiC;4BACjC,MAAM6B,mBAAmBO,mCACvB9D,KACA5B,MACA+B,OACA8C,cACA,OACAtB,gBACA1D;4BAEF+E,mBAAmB,CAACP,iBAAiB,GAAGc;4BACxC;wBACF;oBACA,KAAKnC,2BAAa,CAACK,IAAI;wBAAE;4BACvB,kEAAkE;4BAClE,gEAAgE;4BAChE,4DAA4D;4BAC5D,6DAA6D;4BAC7D,mBAAmB;4BACnB,EAAE;4BACF,iEAAiE;4BACjE,0DAA0D;4BAC1D,iEAAiE;4BACjE,oDAAoD;4BACpD,sBAAsB;4BACtB,EAAE;4BACF,mEAAmE;4BACnE,kEAAkE;4BAClE,mEAAmE;4BACnE,8DAA8D;4BAC9D,8BAA8B;4BAC9B,MAAM8B,mBAAmBO,mCACvB9D,KACA5B,MACA+B,OACA8C,cACA,OACAtB,gBACA1D;4BAEF+E,mBAAmB,CAACP,iBAAiB,GAAGc;4BACxC;wBACF;oBACA;wBACEtF;gBACJ;YACF;QACF;IACF;IACA,MAAM8F,cAAiC;QACrClB,QAAQT,OAAO;QACfY;QACA;QACA;QACAH,QAAQmB,YAAY;KACrB;IACD,OAAOD;AACT;AAEA,SAASH,4CACP5D,GAAW,EACX5B,IAAkB,EAClB+B,KAA+B,EAC/Bf,IAAe,EACf6E,oBAA+D,EAC/DtC,cAAqD;IAErD,6EAA6E;IAC7E,wEAAwE;IACxE,sEAAsE;IACtE,4EAA4E;IAC5E,mEAAmE;IACnE,4EAA4E;IAC5E,wEAAwE;IACxE,2DAA2D;IAE3D,uEAAuE;IACvE,oBAAoB;IACpB,IAAIuC,gBACFD,yBAAyB,OAAO,yBAAyB;IAE3D,MAAM7B,UAAUC,IAAAA,oCAA6B,EAACrC,KAAK5B,MAAM+B,OAAOf,KAAKkD,QAAQ;IAC7E,OAAQF,QAAQ3B,MAAM;QACpB,KAAKC,kBAAW,CAACC,KAAK;YAAE;gBACtB,uEAAuE;gBACvE,2BAA2B;gBAC3B,yEAAyE;gBACzE,uEAAuE;gBACvE,wEAAwE;gBACxE,yEAAyE;gBACzE,gDAAgD;gBAEhD,iDAAiD;gBACjDgB,eAAewC,GAAG,CAChB/E,KAAKkD,QAAQ,EACb8B,IAAAA,8BAAuB,EACrBhC,SACA,wEAAwE;gBACxE,yEAAyE;gBACzE,mEAAmE;gBACnEhB,2BAAa,CAACG,eAAe;gBAGjC,IAAI0C,yBAAyB,WAAW;oBACtCC,gBAAgBD,uBAAuB;gBACzC,OAAO;gBACL,mEAAmE;gBACnE,sBAAsB;gBACxB;gBACA;YACF;QACA,KAAKvD,kBAAW,CAACS,SAAS;YAAE;gBAC1B,iCAAiC;gBACjC,MAAMkD,4BACJjF,KAAKqE,kBAAkB,KAAKC,yBAAkB,CAACY,yBAAyB;gBAC1E,IAAID,2BAA2B;oBAC7B,oEAAoE;oBACpE,sEAAsE;oBACtE,yBAAyB;oBACzB,OAAOR,IAAAA,0CAAmC,EAACzE;gBAC7C;gBAOA;YACF;QACA,KAAKsB,kBAAW,CAACI,OAAO;YAAE;gBAGxB;YACF;QACA,KAAKJ,kBAAW,CAACQ,QAAQ;YAAE;gBAGzB;YACF;QACA;YACEkB;IACJ;IACA,MAAMY,sBAAyD,CAAC;IAChE,IAAI5D,KAAKoD,KAAK,KAAK,MAAM;QACvB,IAAK,MAAMC,oBAAoBrD,KAAKoD,KAAK,CAAE;YACzC,MAAME,YAAYtD,KAAKoD,KAAK,CAACC,iBAAiB;YAC9CO,mBAAmB,CAACP,iBAAiB,GACnCmB,4CACE5D,KACA5B,MACA+B,OACAuC,WACAuB,sBACAtC;QAEN;IACF;IACA,MAAMoC,cAAiC;QACrC3E,KAAKgD,OAAO;QACZY;QACA;QACAkB;QACA9E,KAAK4E,YAAY;KAClB;IACD,OAAOD;AACT;AAEA,SAASD,mCACP9D,GAAW,EACX5B,IAAkB,EAClB+B,KAA+B,EAC/Bf,IAAe,EACfmF,wBAAiC,EACjC5C,cAAqD,EACrD1D,aAA4D;IAE5D,6EAA6E;IAC7E,4EAA4E;IAC5E,uDAAuD;IACvD,EAAE;IACF,uEAAuE;IACvE,0EAA0E;IAC1E,wEAAwE;IACxE,kBAAkB;IAClB,MAAMmE,UAAUC,IAAAA,oCAA6B,EAACrC,KAAK5B,MAAM+B,OAAOf,KAAKkD,QAAQ;IAE7E,IAAIkC,iBAAkD;IAEtD,OAAQpC,QAAQ3B,MAAM;QACpB,KAAKC,kBAAW,CAACC,KAAK;YAAE;gBACtB,yDAAyD;gBACzD6D,iBAAiBJ,IAAAA,8BAAuB,EAAChC,SAASnE;gBAClD;YACF;QACA,KAAKyC,kBAAW,CAACS,SAAS;YAAE;gBAC1B,iCAAiC;gBACjC,IACEiB,QAAQqC,SAAS,IACjBC,IAAAA,4CAAqC,EACnCtC,QAAQnE,aAAa,EACrBA,gBAEF;oBACA,qHAAqH;oBACrH,0CAA0C;oBAC1C,oEAAoE;oBACpE,+FAA+F;oBAC/F,iGAAiG;oBACjGuG,iBAAiBG,4BACf3E,KACA5B,MACA+B,OACAiC,SACAhD,MACAnB;gBAEJ;gBACA;YACF;QACA,KAAKyC,kBAAW,CAACI,OAAO;QACxB,KAAKJ,kBAAW,CAACQ,QAAQ;YAAE;gBACzB,yEAAyE;gBACzE,gFAAgF;gBAChF,IACEwD,IAAAA,4CAAqC,EACnCtC,QAAQnE,aAAa,EACrBA,gBAEF;oBACAuG,iBAAiBG,4BACf3E,KACA5B,MACA+B,OACAiC,SACAhD,MACAnB;gBAEJ;gBACA;YACF;QACA;YACEmE;IACJ;IACA,MAAMY,sBAAyD,CAAC;IAChE,IAAI5D,KAAKoD,KAAK,KAAK,MAAM;QACvB,IAAK,MAAMC,oBAAoBrD,KAAKoD,KAAK,CAAE;YACzC,MAAME,YAAYtD,KAAKoD,KAAK,CAACC,iBAAiB;YAC9CO,mBAAmB,CAACP,iBAAiB,GACnCqB,mCACE9D,KACA5B,MACA+B,OACAuC,WACA6B,4BAA4BC,mBAAmB,MAC/C7C,gBACA1D;QAEN;IACF;IAEA,IAAIuG,mBAAmB,MAAM;QAC3B,2CAA2C;QAC3C7C,eAAewC,GAAG,CAAC/E,KAAKkD,QAAQ,EAAEkC;IACpC;IAEA,8EAA8E;IAC9E,MAAMN,gBACJ,CAACK,4BAA4BC,mBAAmB,OAAO,YAAY;IAErE,MAAMT,cAAiC;QACrC3E,KAAKgD,OAAO;QACZY;QACA;QACAkB;QACA9E,KAAK4E,YAAY;KAClB;IACD,OAAOD;AACT;AAEA,SAASxB,eACPvC,GAAW,EACX5B,IAAkB,EAClB+B,KAA+B,EAC/BiC,OAA0B,EAC1BwC,QAAuB,EACvBxF,IAAe;IAEf,OAAQgD,QAAQ3B,MAAM;QACpB,KAAKC,kBAAW,CAACC,KAAK;YACpB,sEAAsE;YACtEjB,qBACEmF,IAAAA,8BAAuB,EACrB1E,OACAiE,IAAAA,8BAAuB,EAAChC,SAAShB,2BAAa,CAACC,GAAG,GAClDuD,UACAxF;YAGJ;QACF,KAAKsB,kBAAW,CAACI,OAAO;YAAE;gBACxB,mEAAmE;gBACnE,+CAA+C;gBAC/C,OAAQsB,QAAQnE,aAAa;oBAC3B,KAAKmD,2BAAa,CAACC,GAAG;oBACtB,KAAKD,2BAAa,CAACM,UAAU;oBAC7B,KAAKN,2BAAa,CAACK,IAAI;wBAErB;oBACF,KAAKL,2BAAa,CAACG,eAAe;wBAChC,4DAA4D;wBAC5D,oEAAoE;wBACpE,kEAAkE;wBAClE,iEAAiE;wBACjE,uBAAuB;wBACvB,IAAIf,WAAWpC,OAAO;4BACpB,kEAAkE;4BAClE,oDAAoD;4BACpD0G,2BACE9E,KACA5B,MACAgE,SACAjC,OACAyE,UACAxF;wBAEJ;wBACA;oBACF;wBACEgD,QAAQnE,aAAa;gBACzB;gBACA;YACF;QACA,KAAKyC,kBAAW,CAACQ,QAAQ;YAAE;gBACzB,oEAAoE;gBACpE,mEAAmE;gBACnE,OAAQkB,QAAQnE,aAAa;oBAC3B,KAAKmD,2BAAa,CAACC,GAAG;oBACtB,KAAKD,2BAAa,CAACM,UAAU;oBAC7B,KAAKN,2BAAa,CAACK,IAAI;wBAGrB;oBACF,KAAKL,2BAAa,CAACG,eAAe;wBAChC,iEAAiE;wBACjE,oEAAoE;wBACpE,qEAAqE;wBACrE,4DAA4D;wBAC5D,oBAAoB;wBACpB,EAAE;wBACF,sEAAsE;wBACtE,oEAAoE;wBACpE,4DAA4D;wBAC5DuD,2BAA2B9E,KAAK5B,MAAMgE,SAASjC,OAAOyE,UAAUxF;wBAChE;oBACF;wBACEgD,QAAQnE,aAAa;gBACzB;gBACA;YACF;QACA,KAAKyC,kBAAW,CAACS,SAAS;YAExB;QACF;YACEiB;IACJ;AAEA,2EAA2E;AAC3E,2EAA2E;AAC3E,yDAAyD;AAC3D;AAEA,SAAS0C,2BACP9E,GAAW,EACX5B,IAAkB,EAClB2G,cAAiC,EACjC5E,KAA+B,EAC/ByE,QAAuB,EACvBxF,IAAe;IAEf,MAAM4F,sBAAsBC,IAAAA,2CAAoC,EAC9DjF,KACA+E;IAEF,OAAQC,oBAAoBvE,MAAM;QAChC,KAAKC,kBAAW,CAACC,KAAK;YACpB,iEAAiE;YACjE,mBAAmB;YACnBuE,0BACE9G,MACA+B,OACAf,KAAKkD,QAAQ,EACb5C,qBACEmF,IAAAA,8BAAuB,EACrB1E,OACAiE,IAAAA,8BAAuB,EAACY,qBAAqB5D,2BAAa,CAACC,GAAG,GAC9DuD,UACAxF;YAIN;QACF,KAAKsB,kBAAW,CAACI,OAAO;YAEtB;QACF,KAAKJ,kBAAW,CAACS,SAAS;QAC1B,KAAKT,kBAAW,CAACQ,QAAQ;YAIvB;QACF;YACE8D;IACJ;AACF;AAEA,SAASL,4BACP3E,GAAW,EACX5B,IAAkB,EAClB+B,KAA+B,EAC/B4E,cAAiC,EACjC3F,IAAe,EACfnB,aAA4D;IAE5D,MAAM+G,sBAAsBC,IAAAA,2CAAoC,EAC9DjF,KACA+E;IAEF,IAAIC,oBAAoBvE,MAAM,KAAKC,kBAAW,CAACC,KAAK,EAAE;QACpD,kFAAkF;QAClF,0EAA0E;QAC1E,yEAAyE;QACzE,qEAAqE;QACrE,cAAc;QACd,MAAMwE,iBAAiBf,IAAAA,8BAAuB,EAC5CY,qBACA/G;QAEFiH,0BACE9G,MACA+B,OACAf,KAAKkD,QAAQ,EACb8C,IAAAA,+BAAwB,EAACD;QAE3B,OAAOA;IACT,OAAO;QACL,8CAA8C;QAC9C,MAAME,8BAA8BL;QACpC,IACEN,IAAAA,4CAAqC,EACnCW,4BAA4BpH,aAAa,EACzCA,gBAEF;YACA,wEAAwE;YACxE,yCAAyC;YACzC,MAAMqH,eAAeC,IAAAA,oCAA6B,EAChDF;YAEF,MAAMF,iBAAiBf,IAAAA,8BAAuB,EAC5CkB,cACArH;YAEFiH,0BACE9G,MACA+B,OACAf,KAAKkD,QAAQ,EACb8C,IAAAA,+BAAwB,EAACD;YAE3B,OAAOA;QACT;QACA,OAAQE,4BAA4B5E,MAAM;YACxC,KAAKC,kBAAW,CAACI,OAAO;gBACtB,sEAAsE;gBACtE,OAAO;YACT,KAAKJ,kBAAW,CAACS,SAAS;YAC1B,KAAKT,kBAAW,CAACQ,QAAQ;gBACvB,wEAAwE;gBACxE,uEAAuE;gBACvE,8BAA8B;gBAC9B,OAAO;YACT;gBACEmE;gBACA,OAAO;QACX;IACF;AACF;AAEA,MAAMG,OAAO,KAAO;AAEpB,SAASN,0BACP9G,IAAkB,EAClB+B,KAA+B,EAC/BmC,QAAyB,EACzBmD,OAAmD;IAEnD,sEAAsE;IACtEA,QAAQnI,IAAI,CAAC,CAACoI;QACZ,IAAIA,cAAc,MAAM;YACtB,yEAAyE;YACzE,MAAMC,UAAUC,IAAAA,+BAAwB,EAACxH,MAAM+B,OAAOmC;YACtDuD,IAAAA,yBAAkB,EAAC5F,KAAKD,GAAG,IAAI2F,SAASD;QAC1C;IACF,GAAGF;AACL;AAEA,SAASlC,qCACPnD,KAA+B,EAC/B4E,cAAuB,EACvBe,aAAsB;IAEtB,IAAIA,kBAAkBC,yBAAgB,EAAE;QACtC,0EAA0E;QAC1E,qEAAqE;QACrE,yEAAyE;QACzE,0EAA0E;QAC1E,6DAA6D;QAC7D,2DAA2D;QAC3D,0EAA0E;QAC1E,sEAAsE;QACtE,2EAA2E;QAC3E,qEAAqE;QACrE,OACEhB,mBACAiB,IAAAA,qCAA4B,EAC1BD,yBAAgB,EAChBE,OAAOC,WAAW,CAAC,IAAIC,gBAAgBhG,MAAMiG,cAAc;IAGjE;IACA,uEAAuE;IACvE,OAAOC,IAAAA,2BAAY,EAACP,eAAef;AACrC;AAEA,gFAAgF;AAChF,8EAA8E;AAC9E,6EAA6E;AAC7E,qEAAqE;AACrE,gFAAgF;AAEhF,SAASuB,qBAAqBC,CAAe,EAAEC,CAAe;IAC5D,6EAA6E;IAC7E,wEAAwE;IACxE,UAAU;IAEV,sEAAsE;IACtE,MAAMC,eAAeD,EAAEtI,QAAQ,GAAGqI,EAAErI,QAAQ;IAC5C,IAAIuI,iBAAiB,GAAG;QACtB,OAAOA;IACT;IAEA,4EAA4E;IAC5E,4EAA4E;IAC5E,MAAMC,YAAYF,EAAEjI,KAAK,GAAGgI,EAAEhI,KAAK;IACnC,IAAImI,cAAc,GAAG;QACnB,OAAOA;IACT;IAEA,0EAA0E;IAC1E,0EAA0E;IAC1E,OAAOF,EAAE/H,MAAM,GAAG8H,EAAE9H,MAAM;AAC5B;AAEA,SAASI,SAAS8H,IAAyB,EAAEC,IAAkB;IAC7D,MAAMC,QAAQF,KAAKG,MAAM;IACzBH,KAAKI,IAAI,CAACH;IACVA,KAAKjI,UAAU,GAAGkI;IAClBG,WAAWL,MAAMC,MAAMC;AACzB;AAEA,SAAS3G,SAASyG,IAAyB;IACzC,OAAOA,KAAKG,MAAM,KAAK,IAAI,OAAOH,IAAI,CAAC,EAAE;AAC3C;AAEA,SAASpG,QAAQoG,IAAyB;IACxC,IAAIA,KAAKG,MAAM,KAAK,GAAG;QACrB,OAAO;IACT;IACA,MAAMG,QAAQN,IAAI,CAAC,EAAE;IACrBM,MAAMtI,UAAU,GAAG,CAAC;IACpB,MAAMuI,OAAOP,KAAKQ,GAAG;IACrB,IAAID,SAASD,OAAO;QAClBN,IAAI,CAAC,EAAE,GAAGO;QACVA,KAAKvI,UAAU,GAAG;QAClByI,aAAaT,MAAMO,MAAM;IAC3B;IACA,OAAOD;AACT;AAEA,SAASlI,WAAW4H,IAAyB,EAAEC,IAAkB;IAC/D,MAAMC,QAAQD,KAAKjI,UAAU;IAC7B,IAAIkI,UAAU,CAAC,GAAG;QAChBD,KAAKjI,UAAU,GAAG,CAAC;QACnB,IAAIgI,KAAKG,MAAM,KAAK,GAAG;YACrB,MAAMI,OAAOP,KAAKQ,GAAG;YACrB,IAAID,SAASN,MAAM;gBACjBD,IAAI,CAACE,MAAM,GAAGK;gBACdA,KAAKvI,UAAU,GAAGkI;gBAClBO,aAAaT,MAAMO,MAAML;YAC3B;QACF;IACF;AACF;AAEA,SAAS3H,WAAWyH,IAAyB,EAAEC,IAAkB;IAC/D,MAAMC,QAAQD,KAAKjI,UAAU;IAC7B,IAAIkI,UAAU,CAAC,GAAG;QAChB,IAAIA,UAAU,GAAG;YACfO,aAAaT,MAAMC,MAAM;QAC3B,OAAO;YACL,MAAMS,cAAc,AAACR,QAAQ,MAAO;YACpC,MAAMS,SAASX,IAAI,CAACU,YAAY;YAChC,IAAIf,qBAAqBgB,QAAQV,QAAQ,GAAG;gBAC1C,iCAAiC;gBACjCI,WAAWL,MAAMC,MAAMC;YACzB,OAAO;gBACL,+CAA+C;gBAC/CO,aAAaT,MAAMC,MAAMC;YAC3B;QACF;IACF;AACF;AAEA,SAASG,WACPL,IAAyB,EACzBC,IAAkB,EAClBW,CAAS;IAET,IAAIV,QAAQU;IACZ,MAAOV,QAAQ,EAAG;QAChB,MAAMQ,cAAc,AAACR,QAAQ,MAAO;QACpC,MAAMS,SAASX,IAAI,CAACU,YAAY;QAChC,IAAIf,qBAAqBgB,QAAQV,QAAQ,GAAG;YAC1C,wCAAwC;YACxCD,IAAI,CAACU,YAAY,GAAGT;YACpBA,KAAKjI,UAAU,GAAG0I;YAClBV,IAAI,CAACE,MAAM,GAAGS;YACdA,OAAO3I,UAAU,GAAGkI;YAEpBA,QAAQQ;QACV,OAAO;YACL,+BAA+B;YAC/B;QACF;IACF;AACF;AAEA,SAASD,aACPT,IAAyB,EACzBC,IAAkB,EAClBW,CAAS;IAET,IAAIV,QAAQU;IACZ,MAAMT,SAASH,KAAKG,MAAM;IAC1B,MAAMU,aAAaV,WAAW;IAC9B,MAAOD,QAAQW,WAAY;QACzB,MAAMC,YAAY,AAACZ,CAAAA,QAAQ,CAAA,IAAK,IAAI;QACpC,MAAMa,OAAOf,IAAI,CAACc,UAAU;QAC5B,MAAME,aAAaF,YAAY;QAC/B,MAAMG,QAAQjB,IAAI,CAACgB,WAAW;QAE9B,wEAAwE;QACxE,IAAIrB,qBAAqBoB,MAAMd,QAAQ,GAAG;YACxC,IAAIe,aAAab,UAAUR,qBAAqBsB,OAAOF,QAAQ,GAAG;gBAChEf,IAAI,CAACE,MAAM,GAAGe;gBACdA,MAAMjJ,UAAU,GAAGkI;gBACnBF,IAAI,CAACgB,WAAW,GAAGf;gBACnBA,KAAKjI,UAAU,GAAGgJ;gBAElBd,QAAQc;YACV,OAAO;gBACLhB,IAAI,CAACE,MAAM,GAAGa;gBACdA,KAAK/I,UAAU,GAAGkI;gBAClBF,IAAI,CAACc,UAAU,GAAGb;gBAClBA,KAAKjI,UAAU,GAAG8I;gBAElBZ,QAAQY;YACV;QACF,OAAO,IAAIE,aAAab,UAAUR,qBAAqBsB,OAAOhB,QAAQ,GAAG;YACvED,IAAI,CAACE,MAAM,GAAGe;YACdA,MAAMjJ,UAAU,GAAGkI;YACnBF,IAAI,CAACgB,WAAW,GAAGf;YACnBA,KAAKjI,UAAU,GAAGgJ;YAElBd,QAAQc;QACV,OAAO;YACL,kCAAkC;YAClC;QACF;IACF;AACF&quot;</span><span class="s0">,</span><span class="s1">&quot;ignoreList&quot;</span><span class="s0">:[</span><span class="s2">0</span><span class="s0">]}</span></pre>
</body>
</html>